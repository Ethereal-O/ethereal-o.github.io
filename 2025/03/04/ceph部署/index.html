<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Ethereal">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2025/03/04/ceph部署/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="1. 部署1.1 修改host并配置互信（所有节点都需执行）vim &#x2F;etc&#x2F;hosts 10.244.0.228 ubuntu-vm-2404-test-1 10.244.0.155 ubuntu-vm-2404-test-2 10.244.0.226 ubuntu-vm-2404-test-3  1.2 安装 Docker（所有节点都需执行）sudo apt install docker.io">
<meta property="og:type" content="article">
<meta property="og:title" content="ceph部署">
<meta property="og:url" content="http://example.com/2025/03/04/ceph%E9%83%A8%E7%BD%B2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. 部署1.1 修改host并配置互信（所有节点都需执行）vim &#x2F;etc&#x2F;hosts 10.244.0.228 ubuntu-vm-2404-test-1 10.244.0.155 ubuntu-vm-2404-test-2 10.244.0.226 ubuntu-vm-2404-test-3  1.2 安装 Docker（所有节点都需执行）sudo apt install docker.io">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-03-04T13:58:41.000Z">
<meta property="article:modified_time" content="2025-03-31T11:13:11.582Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/redefine-favicon.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/redefine-favicon.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/redefine-favicon.svg">
    <!--- Page Info-->
    
    <title>
        
            ceph部署 -
        
        Ethereal&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"example.com","root":"/","language":"en"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":false,"id":null},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"Welcome to Ethereal's Blog","subtitle":{"text":["A willing horse needs no spur."],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"links":{"github":null,"instagram":null,"zhihu":null,"twitter":null,"email":null},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.2.1","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Github":{"path":"https://github.com/Ethereal-O/","icon":"fa-brands fa-github"},"CSDN":{"path":"https://blog.csdn.net/weixin_51969975","icon":"fa-brands fa-stack-overflow"},"Links":{"icon":"fa-regular fa-link","submenus":{"Fontawesome":"https://fontawesome.com/search","Iconfont":"https://www.iconfont.cn/","Redefine":"https://redefine-docs.ohevan.com/introduction","Linyu":"https://www.linyu.cool/","Electronic-Waste":"https://blog.electronicwaste.cn/?","Thysrael":"https://thysrael.github.io/?","World-explorer":"https://www.cnblogs.com/world-explorer"}}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":null},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2023/8/1 00:00:00"};
    Global.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Ethereal&#39;s Blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    target="_blank" rel="noopener" href="https://github.com/Ethereal-O/"  >
                                    
                                        
                                            <i class="fa-brands fa-github"></i>
                                        
                                        GITHUB
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_51969975"  >
                                    
                                        
                                            <i class="fa-brands fa-stack-overflow"></i>
                                        
                                        CSDN
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-link"></i>
                                        
                                        LINKS&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://fontawesome.com/search">FONTAWESOME
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://www.iconfont.cn/">ICONFONT
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://redefine-docs.ohevan.com/introduction">REDEFINE
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://www.linyu.cool/">LINYU
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://blog.electronicwaste.cn/?">ELECTRONIC-WASTE
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://thysrael.github.io/?">THYSRAEL
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://www.cnblogs.com/world-explorer">WORLD-EXPLORER
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        target="_blank" rel="noopener" href="https://github.com/Ethereal-O/"  >
                             
                                
                                    <i class="fa-brands fa-github"></i>
                                
                                GITHUB
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_51969975"  >
                             
                                
                                    <i class="fa-brands fa-stack-overflow"></i>
                                
                                CSDN
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-link"></i>
                                
                                LINKS&nbsp;<i class="fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://fontawesome.com/search">FONTAWESOME</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://www.iconfont.cn/">ICONFONT</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://redefine-docs.ohevan.com/introduction">REDEFINE</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://www.linyu.cool/">LINYU</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://blog.electronicwaste.cn/?">ELECTRONIC-WASTE</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://thysrael.github.io/?">THYSRAEL</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://www.cnblogs.com/world-explorer">WORLD-EXPLORER</a>
                            </li>
                        
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">ceph部署</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/favicon.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Ethereal</span>
                            
                                <span class="author-label">Lv4</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2025-03-04 21:58:41</span>
        <span class="mobile">2025-03-04 21:58</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2025-03-31 19:13:11</span>
            <span class="mobile">2025-03-31 19:13</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h2 id="1-部署"><a href="#1-部署" class="headerlink" title="1. 部署"></a>1. 部署</h2><h3 id="1-1-修改host并配置互信（所有节点都需执行）"><a href="#1-1-修改host并配置互信（所有节点都需执行）" class="headerlink" title="1.1 修改host并配置互信（所有节点都需执行）"></a>1.1 修改host并配置互信（所有节点都需执行）</h3><pre><code>vim /etc/hosts
10.244.0.228 ubuntu-vm-2404-test-1
10.244.0.155 ubuntu-vm-2404-test-2
10.244.0.226 ubuntu-vm-2404-test-3
</code></pre>
<h3 id="1-2-安装-Docker（所有节点都需执行）"><a href="#1-2-安装-Docker（所有节点都需执行）" class="headerlink" title="1.2 安装 Docker（所有节点都需执行）"></a>1.2 安装 Docker（所有节点都需执行）</h3><pre><code>sudo apt install docker.io
</code></pre>
<h3 id="1-3-SSH-免密登录（所有节点都需执行）注意必须执行下一步的拷贝公钥才算完成免密"><a href="#1-3-SSH-免密登录（所有节点都需执行）注意必须执行下一步的拷贝公钥才算完成免密" class="headerlink" title="1.3 SSH 免密登录（所有节点都需执行）注意必须执行下一步的拷贝公钥才算完成免密"></a>1.3 SSH 免密登录（所有节点都需执行）注意必须执行下一步的拷贝公钥才算完成免密</h3><pre><code>sudo su # 必须以root身份
ssh-keygen -t rsa
# 拷贝密钥
ssh-copy-id ubuntu-vm-2404-test-1
ssh-copy-id ubuntu-vm-2404-test-2
ssh-copy-id ubuntu-vm-2404-test-3
</code></pre>
<h3 id="1-4-使用-cephadm-安装-ceph-集群（在一台上执行）"><a href="#1-4-使用-cephadm-安装-ceph-集群（在一台上执行）" class="headerlink" title="1.4 使用 cephadm 安装 ceph 集群（在一台上执行）"></a>1.4 使用 cephadm 安装 ceph 集群（在一台上执行）</h3><pre><code># 安装 cephadm
apt install cephadm -y
# 启用集群
cephadm bootstrap --mon-ip 10.244.0.228
# 安装 ceph-cli
apt install ceph-common -y
# 集群状态信息
ceph -s
# 查看节点信息
ceph orch host ls
# 拷贝公钥
ssh-copy-id -f -i /etc/ceph/ceph.pub ubuntu-vm-2404-test-2
ssh-copy-id -f -i /etc/ceph/ceph.pub ubuntu-vm-2404-test-3
# 添加节点
ceph orch host add ubuntu-vm-2404-test-2
ceph orch host add ubuntu-vm-2404-test-3
# 查看节点信息
ceph orch host ls
# 列出可用设备，有延迟，一般不准确
ceph orch device ls
# 添加所有可用磁盘到集群
# 注意，此命令的效果是持久的，会自动添加新的可用的磁盘到集群中。
# https://docs.ceph.com/en/latest/cephadm/services/osd/
# 如果需要取消，可以执行ceph orch apply osd --all-available-devices --unmanaged=true
ceph orch apply osd --all-available-devices
# 添加指定磁盘到集群，磁盘必须未格式化，可以选择某个特定分区
# 不建议使用raw方式，更推荐使用lvm方式：https://docs.ceph.com/en/latest/ceph-volume/intro/ 
# 不会对性能产生明显影响，而且易于管理（易于扩容等）
# bluestore是ceph管理的存储引擎。如果使用raw的话，ceph会在磁盘上做标记为bluestore，但是依赖于lvm方式的不会做标记。
# 无论使用raw还是lvm，都会使用bluestore存储引擎。bluestore替代旧版的filestore引擎，在稳定性与性能上均有提升。
# https://cloud.tencent.com/developer/article/2314578
sudo ceph orch daemon add osd ubuntu-vm-2404-test-2:/dev/sda
sudo ceph orch daemon add osd --method raw ubuntu-vm-2404-test-2:/dev/sda # 不推荐使用
# 查看 osd 状态
ceph osd tree
</code></pre>
<h3 id="1-5-初始化（在一台上执行）"><a href="#1-5-初始化（在一台上执行）" class="headerlink" title="1.5 初始化（在一台上执行）"></a>1.5 初始化（在一台上执行）</h3><pre><code># 创建数据pool
ceph osd pool create test
ceph osd pool set test bulk true
# 创建元数据pool
ceph osd pool create cephfs_metadata 128
# 创建元数据部署
ceph orch apply mds test --placement=&quot;1 ubuntu-vm-2404-test-1&quot;
# 关联数据pool和元数据pool
ceph osd pool application enable test cephfs
# 创建文件系统(其中cephfs为文件系统名字)
ceph fs new cephfs_name cephfs_metadata test
# 创建子卷
ceph fs subvolumegroup create cephfs_name csi
# 创建rgw
ceph orch apply rgw default-realm default-zone --placement=&quot;3 k10 k11 k12&quot;
ceph orch apply rgw infra_rgw --placement=&#39;3 k10 k11 k12&#39; --port=8000
# 创建对象存储
radosgw-admin user create --uid=s3 --display-name=&quot;object_storage&quot; --system
# 记住你的access_key和secret_key
&quot;keys&quot;: [
        &#123;
            &quot;user&quot;: &quot;s3&quot;,
            &quot;access_key&quot;: &quot;ENL7QVDGNNYNNEX3X3VS&quot;,
            &quot;secret_key&quot;: &quot;vaUjPhUkR8yLAdqVD6FRnXGVNrxBNDs9bMWFb6Kb&quot;,
            &quot;active&quot;: true,
            &quot;create_date&quot;: &quot;2025-03-10T02:55:13.039290Z&quot;
        &#125;
    ],
# 创建对象桶
radosgw-admin bucket create --bucket=&lt;bucket-name&gt; --user=&lt;username&gt;


# 创建自定义realm的rgw
# 删除默认zone和zonegroup
radosgw-admin zone list
radosgw-admin zone delete  --rgw-zone default
radosgw-admin zonegroup list
radosgw-admin zonegroup delete  --rgw-zonegroup default
# 创建realm、zone和zonegroup
radosgw-admin realm create --rgw-realm=default --default
radosgw-admin zonegroup create --rgw-zonegroup default --rgw-realm default --master --default
radosgw-admin zone create --rgw-zonegroup default --rgw-zone default --master --default
# 设定default（前面default是命令后面是名字）
radosgw-admin realm default default
radosgw-admin zonegroup default default
radosgw-admin zone default default
# 设定master
radosgw-admin zonegroup get &gt; zonegroup.json
vim zonegroup.json # 将其中is_master字段改为true
radosgw-admin zonegroup set --infile zonegroup.json # 导入配置
# 同步period，要执行两次
radosgw-admin period update --commit
radosgw-admin period update --commit
# 部署rgw，必须指定realm和zone
ceph orch apply rgw default --realm=default --zone=default  --placement=&#39;3 k10 k11 k12&#39;


# 部署rbd
## rbd只需要创建pool即可，不需要部署daemon
ceph osd pool create rbd_pool 64 64
ceph osd pool application enable rbd_pool rbd
## 创建具体的块设备
rbd create -p rbd_pool --image ceph-rbd-demo.img --size 10G
## 查看当前的块设备列表
rbd -p rbd_pool ls
## 查看详细信息
rbd -p rbd_pool info ceph-rbd-demo.img
## 关闭features
rbd -p rbd_pool --image ceph-rbd-demo.img feature disable deep-flatten
rbd -p rbd_pool --image ceph-rbd-demo.img feature disable fast-diff
rbd -p rbd_pool --image ceph-rbd-demo.img feature disable object-map
rbd -p rbd_pool --image ceph-rbd-demo.img feature disable exclusive-lock
## map到本地
rbd map -p rbd_pool --image ceph-rbd-demo.img
## 卸载设备
rbd device unmap -p rbd_pool --image ceph-rbd-demo.img
</code></pre>
<h3 id="1-6-配置密钥（客户端执行）"><a href="#1-6-配置密钥（客户端执行）" class="headerlink" title="1.6 配置密钥（客户端执行）"></a>1.6 配置密钥（客户端执行）</h3><pre><code># 找到某用户密钥
cat /etc/ceph/ceph.client.admin.keyring
# 复制密钥
echo &quot;AQCpx8Zn2nTWMxAAvqX4K3Limi6qYmqh9XKTsw==&quot; &gt; secret
</code></pre>
<p>用户创建流程可以参考<a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/areke/p/17723801.html" >ceph（二）CephX认证授权、用户管理和keyring - areke - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph auth add client.test mon &#x27;allow *&#x27; osd &#x27;allow *&#x27; mds &#x27;allow *&#x27;</span><br><span class="line">ceph auth list</span><br></pre></td></tr></table></figure></div>

<h3 id="1-7-挂载（客户端执行）"><a href="#1-7-挂载（客户端执行）" class="headerlink" title="1.7 挂载（客户端执行）"></a>1.7 挂载（客户端执行）</h3><pre><code>sudo mkdir /mnt/cephfs
sudo mount -t ceph ubuntu-vm-2404-test-1:6789:/ /mnt/cephfs -o name=admin,secretfile=secret

# df -h # 实际容量由于三备份会大约为1/3
Filesystem           Size  Used Avail Use% Mounted on
tmpfs                748M  2.2M  746M   1% /run
/dev/vda1             18G  4.8G   13G  28% /
tmpfs                3.7G   16K  3.7G   1% /dev/shm
tmpfs                5.0M     0  5.0M   0% /run/lock
/dev/vda16           881M   61M  758M   8% /boot
/dev/vda15           105M  6.1M   99M   6% /boot/efi
tmpfs                748M   12K  748M   1% /run/user/0
tmpfs                748M   12K  748M   1% /run/user/1000
10.244.0.228:6789:/   18G     0   18G   0% /mnt/cephfs

# sudo ceph -s
  cluster:
    id:     f020f9e9-f8da-11ef-9430-4eecb663651b
    health: HEALTH_OK

  services:
    mon: 1 daemons, quorum ubuntu-vm-2404-test-1 (age 4h)
    mgr: ubuntu-vm-2404-test-1.suvfjb(active, since 4h), standbys: ubuntu-vm-2404-test-2.ppaxtx
    mds: 1/1 daemons up
    osd: 6 osds: 6 up (since 59m), 6 in (since 59m)

  data:
    volumes: 1/1 healthy
    pools:   3 pools, 145 pgs
    objects: 24 objects, 585 KiB
    usage:   461 MiB used, 56 GiB / 57 GiB avail
    pgs:     145 active+clean
</code></pre>
<h3 id="1-8-客户端"><a href="#1-8-客户端" class="headerlink" title="1.8 客户端"></a>1.8 客户端</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先安装客户端</span></span><br><span class="line">sudo apt install ceph-common</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制密钥和配置，以下两条在服务器端执行</span></span><br><span class="line">sudo scp /etc/ceph/ceph.conf ethereal@10.24.0.118:/home/ethereal/Downloads/ceph</span><br><span class="line">sudo scp /etc/ceph/ceph.client.admin.keyring ethereal@10.244.0.118:/home/ethereal/Downloads/ceph</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以下客户端执行</span></span><br><span class="line">sudo cp ceph.conf /etc/ceph/</span><br><span class="line">sudo cp ceph.client.admin.keyring /etc/ceph</span><br><span class="line">echo &quot;AQCpx8Zn2nTWMxAAvqX4K3Limi6qYmqh9XKTsw==&quot; &gt; secret # 密钥来自于ceph.client.admin.keyring</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">客户端挂载</span></span><br><span class="line">sudo mount -t ceph :/ /mnt/cephfs -o name=admin # 优先挂载v2版本，推荐v2方式，在速度与安全性方面都有提升，https://www.bookstack.cn/read/ceph-en/de5b43971cfd01ae.md#msgr2-protocol</span><br><span class="line"></span><br><span class="line">apt install s3cmd</span><br><span class="line">s3cmd --configure</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 使用终端完成配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Access Key：刚才创建的radosgw user的access_key</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Secret Key：刚才创建的radosgw user的secret_key</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Default Region：默认直接回车，使用US</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">S3 Endpoint：IP地址:port，例如“192.168.64.128:80”</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DNS-style bucket+hostname：“bootstrap_host_ip:80/%(bucket)s”，如<span class="string">&quot;192.168.64.128:80/%(bucket)s&quot;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Encryption password：默认直接回车，不需要密码</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Path to GPG program [/usr/bin/gpg]：默认直接回车</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use HTTPS protocol [No]: no，不使用HTTPS</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HTTP Proxy server name: 默认直接回车</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Test access with supplied credentials? [Y/n] 默认直接回车</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 最后保存设置，会生成/root/.s3cfg文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 修改刚生成的/root/.s3cfg中的三处配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cloudfront_host = [serverIP]（改成自己的服务端的IP）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">host_base = [serverIP]:[Port]（改成自己的服务端的IP和端口）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">host_bucket = [serverIP]:[Port]/%(bucket)（改成自己的服务端的IP和端口）</span></span><br><span class="line">s3cmd ls</span><br><span class="line">s3cmd mb s3://default-bucket # 创建bucket</span><br><span class="line">s3cmd mb s3://default-bucket -v # debug模式</span><br><span class="line">s3cmd put values.yaml s3://default-bucket/values.yaml # 上传文件</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">rbd使用</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># map到本地，其中keyfile内容只有key，例如AQDgb+pnZNLsNhAA2J83AIzrzFDB1AlYGjCoAQ==</span></span></span><br><span class="line">rbd map -p rbd_pool --image ceph-rbd-demo.img</span><br><span class="line">rbd --id admin -m 10.144.96.10:3300,10.144.96.11:3300,10.144.96.12:3300 --keyfile=***stripped*** map rbd_pool/ceph-rbd-demo.img --device-type krbd --options noudev</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 卸载设备</span></span></span><br><span class="line">rbd device unmap -p rbd_pool --image ceph-rbd-demo.img</span><br></pre></td></tr></table></figure></div>

<h3 id="1-9-设置时间"><a href="#1-9-设置时间" class="headerlink" title="1.9 设置时间"></a>1.9 设置时间</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（服务端，所有节点）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启用时间同步</span></span><br><span class="line">timedatectl set-ntp true</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置时区 Asia/Shanghai</span></span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看状态</span></span><br><span class="line">timedatectl status</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（服务端，单个节点）</span></span><br><span class="line">ceph config set mon mon_clock_drift_allowed 0.5</span><br><span class="line">ceph config set mon mon_clock_drift_warn_backoff 10</span><br></pre></td></tr></table></figure></div>

<h3 id="1-10-下线"><a href="#1-10-下线" class="headerlink" title="1.10 下线"></a>1.10 下线</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下线OSD</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除守护进程</span></span><br><span class="line">ceph orch daemon rm osd.0 --force</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除crush图节点</span></span><br><span class="line">ceph osd crush remove osd.0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">剔除osd</span></span><br><span class="line">ceph osd down osd.0</span><br><span class="line">ceph osd out osd.0</span><br><span class="line">ceph auth del osd.0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除osd</span></span><br><span class="line">ceph osd rm osd.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">擦除数据，必须擦除数据后才可重新加入集群</span></span><br><span class="line">wipefs -af /dev/sdb</span><br><span class="line">ceph orch device zap k10 /dev/sdb --force</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下线pool</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除所有相关mds</span></span><br><span class="line">ceph orch rm mds.infra-meta</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">标记pool为fail</span></span><br><span class="line">ceph fs fail cephfs-infra</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前fs状态</span></span><br><span class="line">ceph fs status</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除pool</span></span><br><span class="line">ceph config set mon mon_allow_pool_delete true</span><br><span class="line">ceph osd pool rm infra-meta infra-meta --yes-i-really-really-mean-it</span><br></pre></td></tr></table></figure></div>

<p>删除fs</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ceph fs fail test_cephfs</span><br><span class="line">ceph fs rm test_cephfs --yes-i-really-mean-it</span><br><span class="line">ceph osd pool application disable cephfs_data_pool cephfs --yes-i-really-mean-it</span><br><span class="line">ceph config set mon mon_allow_pool_delete true</span><br><span class="line">ceph osd pool rm cephfs_data_pool cephfs_data_pool --yes-i-really-really-mean-it</span><br><span class="line">ceph osd pool rm cephfs_meta_pool cephfs_meta_pool --yes-i-really-really-mean-it</span><br></pre></td></tr></table></figure></div>

<h3 id="1-11-分层缓存"><a href="#1-11-分层缓存" class="headerlink" title="1.11 分层缓存"></a>1.11 分层缓存</h3><p>缓存模式可以参考<a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/296347582" >ceph 缓存分层 - 知乎 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个缓存层</span></span><br><span class="line">ceph osd tier add cold-storage hot-storage</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置缓存模式</span></span><br><span class="line">ceph osd tier cache-mode hot-storage writeback</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将客户端的流量从存储池重定向到缓存池</span></span><br><span class="line">ceph osd tier set-overlay cold-storage hot-storage</span><br><span class="line"></span><br><span class="line">ceph osd pool set &#123;cachepool&#125; hit_set_type bloom</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; hit_set_count 1</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; hit_set_period 300  # 300s 后触发hitset</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; target_max_bytes 1000000000 # 1G </span><br><span class="line">ceph osd pool set &#123;cachepool&#125; target_max_objects 100 # 100个objects后触发下刷</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; cache_min_flush_age 300 # 300s 后触发下刷</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; cache_min_evict_age 300 # 300s 后触发下刷</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; cache_target_dirty_ratio 0.01</span><br><span class="line">ceph osd pool set &#123;cachepool&#125; cache_target_full_ratio 0.02</span><br></pre></td></tr></table></figure></div>

<h3 id="1-12-划分OSD"><a href="#1-12-划分OSD" class="headerlink" title="1.12 划分OSD"></a>1.12 划分OSD</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导出原本的osd map</span></span><br><span class="line">ceph osd getcrushmap -o ./tmp/crushmap.ori</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">反编译osd map</span></span><br><span class="line">crushtool -d crushmap.ori -o decrushmap.ori</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">定义bucket</span></span><br><span class="line">root hdd &#123;</span><br><span class="line">        id -21           # do not change unnecessarily</span><br><span class="line">        id -22 class hdd         # do not change unnecessarily</span><br><span class="line">        # weight 1.935</span><br><span class="line">        alg straw2</span><br><span class="line">        hash 0  # rjenkins1</span><br><span class="line">        item osd.0 weight 0.488</span><br><span class="line">        item osd.1 weight 0.488</span><br><span class="line">        item osd.2 weight 0.488</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">桶层次：<span class="built_in">type</span> 0 osd，<span class="built_in">type</span> 1 host，<span class="built_in">type</span> 2 chassis，<span class="built_in">type</span> 3 rack，<span class="built_in">type</span> 4 row，<span class="built_in">type</span> 5 pdu，<span class="built_in">type</span> 6 pod，<span class="built_in">type</span> 7 room，<span class="built_in">type</span> 8 datacenter，<span class="built_in">type</span> 9 region，<span class="built_in">type</span> 10 root</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改规则</span></span><br><span class="line">rule ssd&#123;</span><br><span class="line">    id 1</span><br><span class="line">    type replicated</span><br><span class="line">    min_size 1</span><br><span class="line">    max_size 10</span><br><span class="line">    step take d</span><br><span class="line">    step chooseleaf firstn 0 type osd</span><br><span class="line">    step emit</span><br><span class="line">&#125;</span><br><span class="line">rule hdd&#123;</span><br><span class="line">        id 2</span><br><span class="line">        type replicated</span><br><span class="line">        min_size 1</span><br><span class="line">        max_size 10</span><br><span class="line">        step take hdd</span><br><span class="line">        step chooseleaf firstn 0 type osd # 这里是说从规则中选取osd</span><br><span class="line">        step emit</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编译osd map</span></span><br><span class="line">crushtool -c decrushmap.new -o crushmap.new</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导入map</span></span><br><span class="line">ceph osd setcrushmap -i ./crushmap.new</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设定某个存储池的规则</span></span><br><span class="line">ceph osd pool set ssd_pool crush_rule ssd</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改ceph.conf防止回滚，在global中加入如下字段</span></span><br><span class="line">osd_crush_update_on_start=false</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pg手动分配</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前容量</span></span><br><span class="line">ceph osd df</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看某个osd的占用</span></span><br><span class="line">ceph pg ls-by-osd osd.3 | egrep ^1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">移动pg，从3到2</span></span><br><span class="line">ceph osd pg-upmap-items 1.77 3 2</span><br></pre></td></tr></table></figure></div>

<h3 id="1-13-崩溃恢复"><a href="#1-13-崩溃恢复" class="headerlink" title="1.13 崩溃恢复"></a>1.13 崩溃恢复</h3><p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46031767/article/details/128618075" >Ceph集群显示XXX daemons have recently crashed警告-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">列出崩溃信息</span></span><br><span class="line">ceph crash ls-new</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">归档新的崩溃记录</span></span><br><span class="line">ceph crash archive-all</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">集群信息存储位置，在所有节点上都存在</span></span><br><span class="line">cd /var/lib/ceph/&lt;cluster-id&gt;</span><br></pre></td></tr></table></figure></div>

<p>镜像<a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/zyxnhr/p/10555577.html" >008 Ceph集群数据同步 - 梦中泪 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>备份<a class="link"   target="_blank" rel="noopener" href="https://yifan-online.com/zh/km/article/detail/17326" >如何备份和恢复Ceph集群的配置和数据？请分别提供备份和恢复的步骤。 | 壹梵在线网络服务 一凡在线 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">备份集群配置文件：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">备份Ceph配置文件</span></span><br><span class="line">cp /etc/ceph/* &#123;备份目录&#125;</span><br><span class="line">备份MON（监控节点）的数据：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">备份MON的数据</span></span><br><span class="line">ceph mon dump --cluster &#123;集群名&#125; --format json &gt; &#123;备份目录&#125;/mon_dump.json</span><br><span class="line">备份OSD（对象存储守护进程）的数据：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">备份OSD的数据</span></span><br><span class="line">ceph osd dump --cluster &#123;集群名&#125; --format json &gt; &#123;备份目录&#125;/osd_dump.json</span><br><span class="line">备份RGW（对象网关）的数据（如果有）：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">备份RGW的数据</span></span><br><span class="line">radosgw-admin --cluster &#123;集群名&#125; backup export --file &#123;备份目录&#125;/rgw_backup.bin</span><br><span class="line">备份MDS（元数据服务器）的数据（如果有）：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">备份MDS的数据</span></span><br><span class="line">ceph fs dump --cluster &#123;集群名&#125; --format json &gt; &#123;备份目录&#125;/fs_dump.json</span><br><span class="line">ceph mds getmap -o &#123;备份目录&#125;/mdsmap.bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">恢复集群配置文件：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复Ceph配置文件</span></span><br><span class="line">cp &#123;备份目录&#125;/* /etc/ceph/</span><br><span class="line">如果之前的集群已被清空或者不可用，可以重新初始化集群：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新初始化Ceph集群</span></span><br><span class="line">ceph-deploy new &#123;MON节点，多个节点以逗号分隔&#125;</span><br><span class="line">ceph-deploy install &#123;MON节点，多个节点以逗号分隔&#125;</span><br><span class="line">ceph-deploy mon create-initial</span><br><span class="line">恢复MON的数据：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复MON的数据</span></span><br><span class="line">ceph-mon --cluster &#123;集群名&#125; --mkfs -i &#123;MON节点&#125; --keyring /etc/ceph/&#123;集群名&#125;.mon.&#123;MON节点&#125;.keyring</span><br><span class="line">ceph-mon --cluster &#123;集群名&#125; -i &#123;MON节点&#125;</span><br><span class="line">恢复OSD的数据：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复OSD的数据</span></span><br><span class="line">ceph-osd --cluster &#123;集群名&#125; --mkfs -i &#123;OSD节点&#125; --osd-data /var/lib/ceph/osd/&#123;集群名&#125;-&#123;OSD节点&#125;</span><br><span class="line">ceph-osd --cluster &#123;集群名&#125; -i &#123;OSD节点&#125;</span><br><span class="line">恢复RGW的数据（如果有）：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复RGW的数据</span></span><br><span class="line">radosgw-admin --cluster &#123;集群名&#125; backup import --file &#123;备份目录&#125;/rgw_backup.bin</span><br><span class="line">恢复MDS的数据（如果有）：</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复MDS的数据</span></span><br><span class="line">ceph-mds --cluster &#123;集群名&#125; --mkfs -i &#123;MDS节点&#125; --keyring /etc/ceph/&#123;集群名&#125;.mds.&#123;MDS节点&#125;.keyring</span><br><span class="line">ceph-mds --cluster &#123;集群名&#125; -i &#123;MDS节点&#125;</span><br><span class="line">ceph fs new &#123;文件系统名称&#125; &#123;MDS节点1&#125; &#123;MDS节点2&#125;</span><br><span class="line">ceph osd pool create cephfs_metadata 8</span><br><span class="line">ceph osd pool create cephfs_data 8</span><br></pre></td></tr></table></figure></div>

<p>恢复速度设置</p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rados/configuration/osd-config-ref/#recovery" >https://docs.ceph.com/en/latest/rados/configuration/osd-config-ref/#recovery <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/zhongguiyao/p/14256058.html" >ceph数据recovery配置策略（数据recovery流量控制） - 钟桂耀 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">业务优先</span></span><br><span class="line">ceph tell osd.* injectargs &#x27;--osd-max-backfills 1 --osd-recovery-max-active 1 --osd-recovery-max-single-start 1&#x27;</span><br><span class="line">ceph tell osd.* injectargs &#x27;--osd-recovery-sleep 1&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复优先</span></span><br><span class="line">ceph tell osd.* injectargs &#x27;--osd-max-backfills 5 --osd-recovery-max-active 5 --osd-recovery-max-single-start 5&#x27;</span><br><span class="line">ceph tell osd.* injectargs &#x27;--osd-recovery-sleep 0&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以上为临时设置，永久设置需要修改config</span></span><br><span class="line">ceph config set osd osd_recovery_max_active 10</span><br><span class="line">ceph config set osd osd_max_backfills 10</span><br><span class="line">ceph config set osd_recovery_max_single_start 1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要注意，新的osd加入时，会采用默认设置</span></span><br><span class="line">ceph config get osd osd_recovery_max_active</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前运行时配置</span></span><br><span class="line">ceph tell osd.0 config show | grep recovery</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">osd_max_backfills : 一个osd上最多能有多少个pg同时做backfill。其中osd出去的最大backfill数量为osd_max_backfills ，osd进来的最大backfill数量也是osd_max_backfills ，所以每个osd最大的backfill数量为osd_max_backfills * 2；</span><br><span class="line">osd_recovery_sleep: 出队列后先Sleep一段时间，拉长两个Recovery的时间间隔；</span><br><span class="line">osd_recovery_max_active: 每个OSD上同时进行的所有PG的恢复操作（active recovery）的最大数量；（注意是恢复操作，不是恢复PG数，因此会收到下面参数的影响）</span><br><span class="line">osd_recovery_max_single_start: OSD在某个时刻会为一个PG启动恢复操作数；</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">osd_max_backfills:默认值10. 一个osd上承载了多个pg。可能很多pg都需要做第二种recovery,即backfill。 设定这个参数来指明在一个osd上最多能有多少个pg同时做backfill。</span><br><span class="line">osd_recovery_max_active：默认值15. 一个osd上可以承载多个pg, 可能好几个pg都需要recovery,这个值限定该osd最多同时有多少pg做recovery。</span><br><span class="line">osd_recovery_max_single_start：默认值5. 这个值限定了每个pg可以启动recovery操作的最大数。</span><br><span class="line">osd_recovery_max_chunk: 默认值8388608. 设置恢复数据块的大小，以防网络阻塞</span><br><span class="line">osd_recovery_op_priority: 默认值10. osd修复操作的优先级, 可小于该值</span><br><span class="line">osd_recovery_sleep: 默认值0. revocery的间隔</span><br></pre></td></tr></table></figure></div>

<p>模拟坏盘</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前所在位置</span></span><br><span class="line">ll /sys/block/sdc # 输出包含host0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模拟删除</span></span><br><span class="line">echo 1 &gt; /sys/block/sdc/device/delete</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果集群有写入，对应的 OSD 就很快 down 掉了</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">恢复</span></span><br><span class="line">echo &#x27;- - -&#x27; &gt; /sys/class/scsi_host/host0/scan</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">磁盘编号会改变，因此必须删除数据后重新加入osd（参考上面下线过程）</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看pg状态</span></span><br><span class="line">ceph pg dump | grep recover</span><br></pre></td></tr></table></figure></div>

<h3 id="1-14-修改rgw的存储池"><a href="#1-14-修改rgw的存储池" class="headerlink" title="1.14 修改rgw的存储池"></a>1.14 修改rgw的存储池</h3><p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/varden/p/16313200.html" >RGW池放置和存储类（Octopus版本） - Varden - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取zonegroup</span></span><br><span class="line">radosgw-admin zonegroup get</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取zone</span></span><br><span class="line">radosgw-admin zone get</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向区域组default中添加placement temporary</span></span><br><span class="line">radosgw-admin zonegroup placement add \</span><br><span class="line">      --rgw-zonegroup default \</span><br><span class="line">      --placement-id temporary</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向区域中添加placement细节，引用它所属区域组中的placement temporary</span></span><br><span class="line">radosgw-admin zone placement add \</span><br><span class="line">      --rgw-zone default \</span><br><span class="line">      --placement-id temporary \</span><br><span class="line">      --data-pool default.rgw.temporary.data \</span><br><span class="line">      --index-pool default.rgw.temporary.index \</span><br><span class="line">      --data-extra-pool default.rgw.temporary.non-ec</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向区域组中default-placement的placement添加storage-class</span></span><br><span class="line">radosgw-admin zonegroup placement add \</span><br><span class="line">      --rgw-zonegroup default \</span><br><span class="line">      --placement-id default-placement \</span><br><span class="line">      --storage-class COLD</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向区域中添加storageclass细节，指定data-pool</span></span><br><span class="line">radosgw-admin zone placement add \</span><br><span class="line">      --rgw-zone default \</span><br><span class="line">      --placement-id default-placement \</span><br><span class="line">      --storage-class COLD \</span><br><span class="line">      --data-pool default.rgw.cold.data \</span><br><span class="line">      --compression lz4</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设定区域组 default默认放置目标</span></span><br><span class="line">radosgw-admin zonegroup placement default \</span><br><span class="line">      --rgw-zonegroup default \</span><br><span class="line">      --placement-id new-placement</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建bucket时指定placement rule</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用--bucket-location覆盖用户的default_placement</span></span><br><span class="line">s3cmd mb s3://second --bucket-location=&quot;:default-placement&quot; </span><br></pre></td></tr></table></figure></div>

<h3 id="1-15-升级"><a href="#1-15-升级" class="headerlink" title="1.15 升级"></a>1.15 升级</h3><p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/releases/index.html" >Ceph Releases (index) — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/varden/p/15966141.html" >使用 Cephadm 升级 CEPH - Varden - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="1-16-故障处理"><a href="#1-16-故障处理" class="headerlink" title="1.16 故障处理"></a>1.16 故障处理</h3><p><a class="link"   target="_blank" rel="noopener" href="https://lihaijing.gitbooks.io/ceph-handbook/content/Troubleshooting/troubleshooting_osd.html" >2. 常见 OSD 故障处理 · Ceph 运维手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apt remove ceph-osd</span><br><span class="line">systemctl restart ceph.target</span><br><span class="line">ceph orch daemon restart osd.5</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker中磁盘映射关系：</span></span><br><span class="line">docker inspect -f &quot;&#123;&#123;.Mounts&#125;&#125;&quot; 369a1376f78c</span><br><span class="line">[&#123;bind  /sys /sys   true rprivate&#125; &#123;bind  /run/lock/lvm /run/lock/lvm   true rprivate&#125; &#123;bind  /var/log/ceph/e30eab96-fa62-11ef-8818-246e96a3ad74 /var/log/ceph  z true rprivate&#125; &#123;bind  /run/udev /run/udev   true rprivate&#125; &#123;bind  /dev /dev   true rprivate&#125; &#123;bind  /run/lvm /run/lvm   true rprivate&#125; &#123;bind  / /rootfs   true rslave&#125; &#123;bind  /var/lib/ceph/e30eab96-fa62-11ef-8818-246e96a3ad74/osd.0 /var/lib/ceph/osd/ceph-0  z true rprivate&#125; &#123;bind  /var/lib/ceph/e30eab96-fa62-11ef-8818-246e96a3ad74/osd.0/config /etc/ceph/ceph.conf  z true rprivate&#125; &#123;bind  /var/run/ceph/e30eab96-fa62-11ef-8818-246e96a3ad74 /var/run/ceph  z true rprivate&#125; &#123;bind  /var/lib/ceph/e30eab96-fa62-11ef-8818-246e96a3ad74/crash /var/lib/ceph/crash  z true rprivate&#125;]</span><br></pre></td></tr></table></figure></div>

<h3 id="1-17-配额"><a href="#1-17-配额" class="headerlink" title="1.17 配额"></a>1.17 配额</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置用户配额</span></span><br><span class="line">radosgw-admin quota set --quota-scope=user --uid=uat --max-objects=10 --max-size=1024</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置bucket配额</span></span><br><span class="line">radosgw-admin quota set --uid=uat --quota-scope=bucket --max-objects=10 --max-size=1024</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启用禁用用户配额</span></span><br><span class="line">radosgw-admin quota enable --quota-scope=user  --uid=uat</span><br><span class="line">radosgw-admin quota-disable --quota-scope=user  --uid=uat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启用bucket配额</span></span><br><span class="line">radosgw-admin quota enable --quota-scope=bucket  --uid=uat</span><br><span class="line">radosgw-admin quota-disable --quota-scope=bucket  --uid=uat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取配额信息</span></span><br><span class="line">radosgw-admin user info --uid=uat</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取存储池配额</span></span><br><span class="line">ceph osd pool get-quota test_map</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置存储池配额</span></span><br><span class="line">ceph osd pool set-quota &lt;poolname&gt; max_bytes size</span><br></pre></td></tr></table></figure></div>

<h3 id="1-18-测试"><a href="#1-18-测试" class="headerlink" title="1.18 测试"></a>1.18 测试</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">写：必须先执行写并且添加--no-cleanup才可以执行读</span><br><span class="line">rados bench -p rbd 10 write --no-cleanup</span><br><span class="line"></span><br><span class="line">顺序读：</span><br><span class="line">rados bench -p rbd 10 seq</span><br><span class="line"></span><br><span class="line">随机读：</span><br><span class="line">rados bench -p rbd 10 rand</span><br><span class="line"></span><br><span class="line">删除rados bench命令创建的数据：</span><br><span class="line">rados -p rbd cleanup</span><br><span class="line"></span><br><span class="line">查看磁盘io:</span><br><span class="line">`iotop -P`</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cur 是current的缩写 </span><br><span class="line">cur MB/s 当前速度</span><br><span class="line">avg MB/s 平均速度</span><br><span class="line">Bandwidth (MB/sec): 吞吐量</span><br><span class="line">Average IOPS: 平均iops</span><br><span class="line">Stddev IOPS: 标准偏差</span><br><span class="line">Average Latency(s): 平均延迟</span><br></pre></td></tr></table></figure></div>

<p>测试结果：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hdd write</span></span><br><span class="line">Total time run:         10.3334</span><br><span class="line">Total writes made:      559</span><br><span class="line">Write size:             4194304</span><br><span class="line">Object size:            4194304</span><br><span class="line">Bandwidth (MB/sec):     216.387</span><br><span class="line">Stddev Bandwidth:       10.8403</span><br><span class="line">Max bandwidth (MB/sec): 232</span><br><span class="line">Min bandwidth (MB/sec): 204</span><br><span class="line">Average IOPS:           54</span><br><span class="line">Stddev IOPS:            2.71006</span><br><span class="line">Max IOPS:               58</span><br><span class="line">Min IOPS:               51</span><br><span class="line">Average Latency(s):     0.294018</span><br><span class="line">Stddev Latency(s):      0.194231</span><br><span class="line">Max latency(s):         0.892445</span><br><span class="line">Min latency(s):         0.024855</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hdd <span class="built_in">read</span></span></span><br><span class="line">Total time run:       2.664</span><br><span class="line">Total reads made:     559</span><br><span class="line">Read size:            4194304</span><br><span class="line">Object size:          4194304</span><br><span class="line">Bandwidth (MB/sec):   839.338</span><br><span class="line">Average IOPS:         209</span><br><span class="line">Stddev IOPS:          73.5391</span><br><span class="line">Max IOPS:             283</span><br><span class="line">Min IOPS:             179</span><br><span class="line">Average Latency(s):   0.0730044</span><br><span class="line">Max latency(s):       0.495011</span><br><span class="line">Min latency(s):       0.00412251  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssd write</span></span><br><span class="line">Total time run:         10.0774</span><br><span class="line">Total writes made:      1787</span><br><span class="line">Write size:             4194304</span><br><span class="line">Object size:            4194304</span><br><span class="line">Bandwidth (MB/sec):     709.311</span><br><span class="line">Stddev Bandwidth:       60.0577</span><br><span class="line">Max bandwidth (MB/sec): 784</span><br><span class="line">Min bandwidth (MB/sec): 608</span><br><span class="line">Average IOPS:           177</span><br><span class="line">Stddev IOPS:            15.0144</span><br><span class="line">Max IOPS:               196</span><br><span class="line">Min IOPS:               152</span><br><span class="line">Average Latency(s):     0.0899146</span><br><span class="line">Stddev Latency(s):      0.0832786</span><br><span class="line">Max latency(s):         1.12338</span><br><span class="line">Min latency(s):         0.0246071  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssd <span class="built_in">read</span></span></span><br><span class="line">Total time run:       5.86502</span><br><span class="line">Total reads made:     1787</span><br><span class="line">Read size:            4194304</span><br><span class="line">Object size:          4194304</span><br><span class="line">Bandwidth (MB/sec):   1218.75</span><br><span class="line">Average IOPS:         304</span><br><span class="line">Stddev IOPS:          27.335</span><br><span class="line">Max IOPS:             312</span><br><span class="line">Min IOPS:             244</span><br><span class="line">Average Latency(s):   0.0513641</span><br><span class="line">Max latency(s):       0.241155</span><br><span class="line">Min latency(s):       0.00696541  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cache write</span></span><br><span class="line">Total time run:         10.0538</span><br><span class="line">Total writes made:      1939</span><br><span class="line">Write size:             4194304</span><br><span class="line">Object size:            4194304</span><br><span class="line">Bandwidth (MB/sec):     771.446</span><br><span class="line">Stddev Bandwidth:       61.3638</span><br><span class="line">Max bandwidth (MB/sec): 836</span><br><span class="line">Min bandwidth (MB/sec): 660</span><br><span class="line">Average IOPS:           192</span><br><span class="line">Stddev IOPS:            15.3409</span><br><span class="line">Max IOPS:               209</span><br><span class="line">Min IOPS:               165</span><br><span class="line">Average Latency(s):     0.0827728</span><br><span class="line">Stddev Latency(s):      0.0337953</span><br><span class="line">Max latency(s):         0.290505</span><br><span class="line">Min latency(s):         0.0306568  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cache <span class="built_in">read</span></span></span><br><span class="line">Total time run:       6.85431</span><br><span class="line">Total reads made:     1939</span><br><span class="line">Read size:            4194304</span><br><span class="line">Object size:          4194304</span><br><span class="line">Bandwidth (MB/sec):   1131.55</span><br><span class="line">Average IOPS:         282</span><br><span class="line">Stddev IOPS:          40.6596</span><br><span class="line">Max IOPS:             349</span><br><span class="line">Min IOPS:             228</span><br><span class="line">Average Latency(s):   0.0553511</span><br><span class="line">Max latency(s):       0.252595</span><br><span class="line">Min latency(s):       0.00646825</span><br></pre></td></tr></table></figure></div>

<h3 id="1-19-修改监控"><a href="#1-19-修改监控" class="headerlink" title="1.19 修改监控"></a>1.19 修改监控</h3><p>查看当前地址</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ceph config get mgr</span></span><br><span class="line">WHO     MASK  LEVEL     OPTION                                VALUE</span><br><span class="line">                                 RO</span><br><span class="line">mgr           advanced  container_image                       quay.io/ceph/ceph@sha256:41d3f5e46ff7de28544cc8869fdea13fca824dcef83936cb3288ed9de935e4de  *</span><br><span class="line">mgr           advanced  mgr/cephadm/container_init            True</span><br><span class="line">                                 *</span><br><span class="line">mgr           advanced  mgr/cephadm/migration_current         7</span><br><span class="line">                                 *</span><br><span class="line">mgr           advanced  mgr/dashboard/ALERTMANAGER_API_HOST   http://cluster.svc:9093</span><br><span class="line">                                 *</span><br><span class="line">mgr           advanced  mgr/dashboard/GRAFANA_API_SSL_VERIFY  false</span><br><span class="line">                                 *</span><br><span class="line">mgr           advanced  mgr/dashboard/GRAFANA_API_URL         https://cluster.svc:3000</span><br><span class="line"></span><br><span class="line">mgr           advanced  mgr/dashboard/PROMETHEUS_API_HOST     http://cluster.svc:9095</span><br><span class="line">                                 *</span><br><span class="line">mgr           advanced  mgr/dashboard/RGW_API_ACCESS_KEY      &#123;&quot;default&quot;: &quot;HKCWLKQKXS1G1L2BV7A4&quot;&#125;</span><br><span class="line">                                 *</span><br><span class="line">mgr           advanced  mgr/dashboard/RGW_API_SECRET_KEY      &#123;&quot;default&quot;: &quot;qGCwWDjirgdCLzoIOhdtJvMnWiPqOWwIaGoZofSw&quot;&#125;                                    *</span><br><span class="line">mgr           advanced  mgr/dashboard/ssl_server_port         8443</span><br><span class="line">                                 *</span><br><span class="line">global        basic     mgr/orchestrator/orchestrator         cephadm</span><br></pre></td></tr></table></figure></div>

<p>修改地址</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ceph dashboard set-alertmanager-api-host https://cluster.svc:9093</span><br><span class="line">ceph dashboard set-grafana-api-url https://cluster.svc:3000</span><br><span class="line">ceph dashboard set-prometheus-api-host https://cluster.svc:9095</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line">ceph config set mgr mgr/dashboard/ALERTMANAGER_API_HOST https://cluster.svc:9093</span><br><span class="line">ceph config set mgr mgr/dashboard/GRAFANA_API_URL https://cluster.svc:3000</span><br><span class="line">ceph config set mgr mgr/dashboard/PROMETHEUS_API_HOST https://cluster.svc:9095</span><br></pre></td></tr></table></figure></div>

<h2 id="2-部署到k8s"><a href="#2-部署到k8s" class="headerlink" title="2. 部署到k8s"></a>2. 部署到k8s</h2><h4 id="2-0-准备工作（服务端执行）"><a href="#2-0-准备工作（服务端执行）" class="headerlink" title="2.0 准备工作（服务端执行）"></a>2.0 准备工作（服务端执行）</h4><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确保ceph正常运行</span></span><br><span class="line">ceph -s</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确保存在mon</span></span><br><span class="line">ceph mon dump</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取key</span></span><br><span class="line">ceph auth get client.admin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建data池</span></span><br><span class="line">ceph osd pool create test 8 8</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建元数据池</span></span><br><span class="line">ceph osd pool create cephfs_metadata 8 8</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关联元数据与data</span></span><br><span class="line">ceph fs new cephfs cephfs_metadata test</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建子卷</span></span><br><span class="line">ceph fs subvolumegroup create cephfs csi </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">volume代表一个文件系统卷，subvolume可以理解成volume下的文件夹</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">volumegroup与subvolumegroup可以对volume或subvolume进行方便的权限管理</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">https://elrond.wang/2021/08/16/CephFS-subvolume/</span></span><br></pre></td></tr></table></figure></div>

<p>子卷调整配额</p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/QTM_Gitee/article/details/115440845" >管理CephFS：创建、删除及操作子卷、快照和子卷组-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/5/html/file_system_guide/ceph-file-system-subvolumes#ceph-file-system-subvolumes" >4.3. Ceph 文件系统子卷 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="2-1-下载csi"><a href="#2-1-下载csi" class="headerlink" title="2.1 下载csi"></a>2.1 下载csi</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:ceph/ceph-csi.git --depth=1</span><br><span class="line">cd ceph-csi/deploy/cephfs/kubernetes</span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-修改配置文件"><a href="#2-2-修改配置文件" class="headerlink" title="2.2 修改配置文件"></a>2.2 修改配置文件</h3><h4 id="2-2-1-修改conf"><a href="#2-2-1-修改conf" class="headerlink" title="2.2.1 修改conf"></a>2.2.1 修改conf</h4><p>其中，clusterID是集群ID，可以通过在服务器端命令<code>ceph -s</code>获得，mon信息可以通过命令<code>ceph mon dump</code>获得</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> csi-config-map.yaml</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">data:</span><br><span class="line">  config.json: |-</span><br><span class="line">    [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;clusterID&quot;: &quot;c7b4xxf7-c61e-4668-9xx0-82c9xx5e3696&quot;,</span><br><span class="line">        &quot;monitors&quot;: [</span><br><span class="line">          &quot;xxx.xxx.xxx.xxx:3300&quot;, # v2方式</span><br><span class="line">          &quot;xxx.xxx.xxx.xxx:6789&quot; # v1方式</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-csi-config</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sudo ceph -s</span></span><br><span class="line">  cluster:</span><br><span class="line">    id:     f020f9e9-f8da-11ef-9430-4eecb663651b</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum ubuntu-vm-2404-test-1 (age 22h)</span><br><span class="line">    mgr: ubuntu-vm-2404-test-1.suvfjb(active, since 22h), standbys: ubuntu-vm-2404-test-2.ppaxtx</span><br><span class="line">    mds: 1/1 daemons up</span><br><span class="line">    osd: 6 osds: 6 up (since 19h), 6 in (since 19h)</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    volumes: 1/1 healthy</span><br><span class="line">    pools:   3 pools, 145 pgs</span><br><span class="line">    objects: 278 objects, 1001 MiB</span><br><span class="line">    usage:   3.4 GiB used, 53 GiB / 57 GiB avail</span><br><span class="line">    pgs:     145 active+clean</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sudo ceph mon dump</span></span><br><span class="line">epoch 1</span><br><span class="line">fsid f020f9e9-f8da-11ef-9430-4eecb663651b</span><br><span class="line">last_changed 2025-03-04T09:28:10.173718+0000</span><br><span class="line">created 2025-03-04T09:28:10.173718+0000</span><br><span class="line">min_mon_release 19 (squid)</span><br><span class="line">election_strategy: 1</span><br><span class="line">0: [v2:10.244.0.228:3300/0,v1:10.244.0.228:6789/0] mon.ubuntu-vm-2404-test-1</span><br><span class="line">dumped monmap epoch 1</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-2-修改secret"><a href="#2-2-2-修改secret" class="headerlink" title="2.2.2 修改secret"></a>2.2.2 修改secret</h4><p>其中，userKey和adminKey都可通过命令<code>ceph auth get client.admin</code>获得</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> secret.yaml</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: csi-cephfs-secret</span><br><span class="line">  namespace: default</span><br><span class="line">stringData:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Required <span class="keyword">for</span> statically provisioned volumes</span></span><br><span class="line">  userID: admin</span><br><span class="line">  userKey: AQBg4llf+9CAGdsAds4tQzS+0O7dscB5ZTiTEQ==</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Required <span class="keyword">for</span> dynamically provisioned volumes</span></span><br><span class="line">  adminID: admin</span><br><span class="line">  adminKey: AQBg4llf+9CAGdsAds4tQzS+0O7dscB5ZTiTEQ==</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sudo ceph auth get client.admin</span></span><br><span class="line">[client.admin]</span><br><span class="line">        key = AQCpx8Zn2nTWMxAAvqX4K3Limi6qYmqh9XKTsw==</span><br><span class="line">        caps mds = &quot;allow *&quot;</span><br><span class="line">        caps mgr = &quot;allow *&quot;</span><br><span class="line">        caps mon = &quot;allow *&quot;</span><br><span class="line">        caps osd = &quot;allow *&quot;</span><br></pre></td></tr></table></figure></div>

<p>如果是rbd，那么类似</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: csi-rbd-secret</span><br><span class="line">stringData:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Required <span class="keyword">for</span> statically provisioned volumes</span></span><br><span class="line">  userID: admin</span><br><span class="line">  userKey: AQDDv9pnTzbFBhAAPal5qxNBNq3KFMRXbaWvMg==</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Required <span class="keyword">for</span> dynamically provisioned volumes</span></span><br><span class="line">  adminID: admin</span><br><span class="line">  adminKey: AQDDv9pnTzbFBhAAPal5qxNBNq3KFMRXbaWvMg==</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-3-创建剩余的配置文件"><a href="#2-2-3-创建剩余的配置文件" class="headerlink" title="2.2.3 创建剩余的配置文件"></a>2.2.3 创建剩余的配置文件</h4><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim csi-config-map-kms.yaml</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">data:</span><br><span class="line">  config.json: |-</span><br><span class="line">    &#123;&#125;</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-csi-encryption-kms-config</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-4-创建sc"><a href="#2-2-4-创建sc" class="headerlink" title="2.2.4 创建sc"></a>2.2.4 创建sc</h4><p>其中，fsName是文件系统名称，pool要对应到一个数据类型的池中，clusterID与前面配置一致，mountOptions要去掉，不然pod会挂载不上，reclaimPolicy表示当pod删除后对应的文件是否要删除。添加kernelMountOptions: ms_mode&#x3D;prefer-crc后即可启用v2连接。</p>
<p>用法详见<a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi/blob/devel/examples/cephfs/storageclass.yaml" >ceph-csi&#x2F;examples&#x2F;cephfs&#x2F;storageclass.yaml at devel · ceph&#x2F;ceph-csi · GitHub <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> storageclass.yaml</span></span><br><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: csi-cephfs-sc</span><br><span class="line">provisioner: cephfs.csi.ceph.com</span><br><span class="line">parameters:</span><br><span class="line">  clusterID: c7b43ef7-c61e-4668-9970-82c9775e3696</span><br><span class="line">  fsName: cephfs</span><br><span class="line">  pool: test</span><br><span class="line">  kernelMountOptions: ms_mode=prefer-crc</span><br><span class="line">  csi.storage.k8s.io/provisioner-secret-name: csi-cephfs-secret</span><br><span class="line">  csi.storage.k8s.io/provisioner-secret-namespace: default</span><br><span class="line">  csi.storage.k8s.io/controller-expand-secret-name: csi-cephfs-secret</span><br><span class="line">  csi.storage.k8s.io/controller-expand-secret-namespace: default</span><br><span class="line">  csi.storage.k8s.io/node-stage-secret-name: csi-cephfs-secret</span><br><span class="line">  csi.storage.k8s.io/node-stage-secret-namespace: default</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">allowVolumeExpansion: true</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mountOptions:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  - discard</span></span><br></pre></td></tr></table></figure></div>

<p>rbd创建的sc如下：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">   name: csi-rbd-sc</span><br><span class="line">provisioner: rbd.csi.ceph.com</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">If topology based provisioning is desired, delayed provisioning of</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">PV is required and is enabled using the following attribute</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">For further information <span class="built_in">read</span> TODO&lt;doc&gt;</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">volumeBindingMode: WaitForFirstConsumer</span></span><br><span class="line">parameters:</span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(required) String representing a Ceph cluster to provision storage from.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Should be unique across all Ceph clusters <span class="keyword">in</span> use <span class="keyword">for</span> provisioning,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">cannot be greater than 36 bytes <span class="keyword">in</span> length, and should remain immutable <span class="keyword">for</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">the lifetime of the StorageClass <span class="keyword">in</span> use.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Ensure to create an entry <span class="keyword">in</span> the configmap named ceph-csi-config, based on</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">csi-config-map-sample.yaml, to accompany the string chosen to</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">represent the Ceph cluster <span class="keyword">in</span> clusterID below</span></span><br><span class="line">   clusterID: 06be027c-04c2-11f0-ace2-246e96a3ad74</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) If you want to use erasure coded pool with RBD, you need to</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">create two pools. one erasure coded and one replicated.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">You need to specify the replicated pool here <span class="keyword">in</span> the `pool` parameter, it is</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">used <span class="keyword">for</span> the metadata of the images.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">The erasure coded pool must be <span class="built_in">set</span> as the `dataPool` parameter below.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">dataPool: &lt;ec-data-pool&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(required) Ceph pool into <span class="built_in">which</span> the RBD image shall be created</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) If the topologyConstrainedPools is provided</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">eg: pool: rbdpool</span></span><br><span class="line">   pool: rbd_pool</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) RBD image features, CSI creates image with image-format 2 CSI</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">RBD currently supports `layering`, `journaling`, `exclusive-lock`,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">`object-map`, `fast-diff`, `deep-flatten` features.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Refer https://docs.ceph.com/en/latest/rbd/rbd-config-ref/<span class="comment">#image-features</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash"><span class="keyword">for</span> image feature dependencies.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">imageFeatures: layering,journaling,exclusive-lock,object-map,fast-diff</span></span><br><span class="line">   imageFeatures: &quot;layering&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Options to pass to the `mkfs` <span class="built_in">command</span> <span class="keyword">while</span> creating the</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">filesystem on the RBD device. Check the man-page <span class="keyword">for</span> the `mkfs` <span class="built_in">command</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash"><span class="keyword">for</span> the filesystem <span class="keyword">for</span> more details. When `mkfsOptions` is <span class="built_in">set</span> here, the</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">defaults will not be used, consider including them <span class="keyword">in</span> this parameter.</span></span><br><span class="line"><span class="meta prompt_">   #</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">   <span class="comment"># The default options depend on the csi.storage.k8s.io/fstype setting:</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">- ext4: <span class="string">&quot;-m0 -Enodiscard,lazy_itable_init=1,lazy_journal_init=1&quot;</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">- xfs: <span class="string">&quot;-K&quot;</span></span></span><br><span class="line"><span class="meta prompt_">   #</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">   <span class="comment"># mkfsOptions: &quot;-m0 -Ediscard -i1024&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Specifies whether to try other mounters <span class="keyword">in</span> <span class="keyword">case</span> <span class="keyword">if</span> the current</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">mounter fails to mount the rbd image <span class="keyword">for</span> any reason. True means fallback</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">to next mounter, default is <span class="built_in">set</span> to <span class="literal">false</span>.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Note: tryOtherMounters is currently useful to fallback from krbd to rbd-nbd</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash"><span class="keyword">in</span> <span class="keyword">case</span> <span class="keyword">if</span> any of the specified imageFeatures is not supported by krbd</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">driver on node scheduled <span class="keyword">for</span> application pod launch, but <span class="keyword">in</span> the future this</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">should work with any mounter <span class="built_in">type</span>.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">tryOtherMounters: <span class="literal">false</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) mapOptions is a comma-separated list of map options.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For krbd options refer</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">https://docs.ceph.com/docs/master/man/8/rbd/<span class="comment">#kernel-rbd-krbd-options</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For nbd options refer</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">https://docs.ceph.com/docs/master/man/8/rbd-nbd/<span class="comment">#options</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Format:</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">mapOptions: <span class="string">&quot;&lt;mounter&gt;:op1,op2;&lt;mounter&gt;:op1,op2&quot;</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">An empty mounter field is treated as krbd <span class="built_in">type</span> <span class="keyword">for</span> compatibility.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">eg:</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">mapOptions: <span class="string">&quot;krbd:lock_on_read,queue_depth=1024;nbd:try-netlink&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) unmapOptions is a comma-separated list of unmap options.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For krbd options refer</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">https://docs.ceph.com/docs/master/man/8/rbd/<span class="comment">#kernel-rbd-krbd-options</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For nbd options refer</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">https://docs.ceph.com/docs/master/man/8/rbd-nbd/<span class="comment">#options</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Format:</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">unmapOptions: <span class="string">&quot;&lt;mounter&gt;:op1,op2;&lt;mounter&gt;:op1,op2&quot;</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">An empty mounter field is treated as krbd <span class="built_in">type</span> <span class="keyword">for</span> compatibility.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">eg:</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">unmapOptions: <span class="string">&quot;krbd:force;nbd:force&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">The secrets have to contain Ceph credentials with required access</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">to the <span class="string">&#x27;pool&#x27;</span>.</span></span><br><span class="line">   csi.storage.k8s.io/provisioner-secret-name: csi-rbd-secret</span><br><span class="line">   csi.storage.k8s.io/provisioner-secret-namespace: ceph-storage</span><br><span class="line">   csi.storage.k8s.io/controller-expand-secret-name: csi-rbd-secret</span><br><span class="line">   csi.storage.k8s.io/controller-expand-secret-namespace: ceph-storage</span><br><span class="line">   csi.storage.k8s.io/node-stage-secret-name: csi-rbd-secret</span><br><span class="line">   csi.storage.k8s.io/node-stage-secret-namespace: ceph-storage</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Specify the filesystem <span class="built_in">type</span> of the volume. If not specified,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">csi-provisioner will <span class="built_in">set</span> default as `ext4`.</span></span><br><span class="line">   csi.storage.k8s.io/fstype: ext4</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) uncomment the following to use rbd-nbd as mounter</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">on supported nodes</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">mounter: rbd-nbd</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) ceph client <span class="built_in">log</span> location, eg: rbd-nbd</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">By default host-path /var/log/ceph of node is bind-mounted into</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">csi-rbdplugin pod at /var/log/ceph mount path. This is to configure</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">target bindmount path used inside container <span class="keyword">for</span> ceph clients logging.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">See docs/design/proposals/rbd-nbd.md <span class="keyword">for</span> available configuration options.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">cephLogDir: /var/log/ceph</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) ceph client <span class="built_in">log</span> strategy</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">By default, <span class="built_in">log</span> file belonging to a particular volume will be deleted</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">on unmap, but you can choose to just compress instead of deleting it</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">or even preserve the <span class="built_in">log</span> file <span class="keyword">in</span> text format as it is.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Available options `remove` or `compress` or `preserve`</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">cephLogStrategy: remove</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Prefix to use <span class="keyword">for</span> naming RBD images.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">If omitted, defaults to <span class="string">&quot;csi-vol-&quot;</span>.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">volumeNamePrefix: <span class="string">&quot;foo-bar-&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Instruct the plugin it has to encrypt the volume</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">By default it is disabled. Valid values are <span class="string">&quot;true&quot;</span> or <span class="string">&quot;false&quot;</span>.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">A string is expected here, i.e. <span class="string">&quot;true&quot;</span>, not <span class="literal">true</span>.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">encrypted: <span class="string">&quot;true&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Select the encryption <span class="built_in">type</span> when encrypted: <span class="string">&quot;true&quot;</span> above.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Valid values are:</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">  <span class="string">&quot;file&quot;</span>: Enable file encryption on the mounted filesystem</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">  <span class="string">&quot;block&quot;</span>: Encrypt RBD block device</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">When unspecified assume <span class="built_in">type</span> <span class="string">&quot;block&quot;</span>. <span class="string">&quot;file&quot;</span> and <span class="string">&quot;block&quot;</span> are</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">mutually exclusive.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">encryptionType: <span class="string">&quot;block&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) Use external key management system <span class="keyword">for</span> encryption passphrases by</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">specifying a unique ID matching KMS ConfigMap. The ID is only used <span class="keyword">for</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">correlation to configmap entry.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">encryptionKMSID: &lt;kms-config-id&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Add topology constrained pools configuration, <span class="keyword">if</span> topology based pools</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">are setup, and topology constrained provisioning is required.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For further information <span class="built_in">read</span> TODO&lt;doc&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">topologyConstrainedPools: |</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">  [&#123;<span class="string">&quot;poolName&quot;</span>:<span class="string">&quot;pool0&quot;</span>,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">    <span class="string">&quot;dataPool&quot;</span>:<span class="string">&quot;ec-pool0&quot;</span> <span class="comment"># optional, erasure-coded pool for data</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">    <span class="string">&quot;domainSegments&quot;</span>:[</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">      &#123;<span class="string">&quot;domainLabel&quot;</span>:<span class="string">&quot;region&quot;</span>,<span class="string">&quot;value&quot;</span>:<span class="string">&quot;east&quot;</span>&#125;,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">      &#123;<span class="string">&quot;domainLabel&quot;</span>:<span class="string">&quot;zone&quot;</span>,<span class="string">&quot;value&quot;</span>:<span class="string">&quot;zone1&quot;</span>&#125;]&#125;,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">   &#123;<span class="string">&quot;poolName&quot;</span>:<span class="string">&quot;pool1&quot;</span>,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">    <span class="string">&quot;dataPool&quot;</span>:<span class="string">&quot;ec-pool1&quot;</span> <span class="comment"># optional, erasure-coded pool for data</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">    <span class="string">&quot;domainSegments&quot;</span>:[</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">      &#123;<span class="string">&quot;domainLabel&quot;</span>:<span class="string">&quot;region&quot;</span>,<span class="string">&quot;value&quot;</span>:<span class="string">&quot;east&quot;</span>&#125;,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">      &#123;<span class="string">&quot;domainLabel&quot;</span>:<span class="string">&quot;zone&quot;</span>,<span class="string">&quot;value&quot;</span>:<span class="string">&quot;zone2&quot;</span>&#125;]&#125;,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">   &#123;<span class="string">&quot;poolName&quot;</span>:<span class="string">&quot;pool2&quot;</span>,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">    <span class="string">&quot;dataPool&quot;</span>:<span class="string">&quot;ec-pool2&quot;</span> <span class="comment"># optional, erasure-coded pool for data</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">    <span class="string">&quot;domainSegments&quot;</span>:[</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">      &#123;<span class="string">&quot;domainLabel&quot;</span>:<span class="string">&quot;region&quot;</span>,<span class="string">&quot;value&quot;</span>:<span class="string">&quot;west&quot;</span>&#125;,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">      &#123;<span class="string">&quot;domainLabel&quot;</span>:<span class="string">&quot;zone&quot;</span>,<span class="string">&quot;value&quot;</span>:<span class="string">&quot;zone1&quot;</span>&#125;]&#125;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">  ]</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">Image striping, Refer https://docs.ceph.com/en/latest/man/8/rbd/<span class="comment">#striping</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For more details</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) stripe unit <span class="keyword">in</span> bytes.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">stripeUnit: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) objects to stripe over before looping.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">stripeCount: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) The object size <span class="keyword">in</span> bytes.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">objectSize: &lt;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">rbd volume QoS.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">QoS provides settings <span class="keyword">for</span> rbd volume <span class="built_in">read</span>/write iops</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">and <span class="built_in">read</span>/write bandwidth. There are 4 base qos parameters</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">among them, when <span class="built_in">users</span> apply <span class="keyword">for</span> a volume capacity equal</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">to or less than BaseVolSizebytes, use base qos <span class="built_in">limit</span>.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">For the portion of capacity exceeding BaseVolSizebytes,</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">QoS will be increased <span class="keyword">in</span> steps <span class="built_in">set</span> per GiB. If the step</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">size parameter per GiB is not provided, only base QoS <span class="built_in">limit</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">will be used and not associated with capacity size.</span></span><br><span class="line"><span class="meta prompt_">   #</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">   <span class="comment"># note: currently supports rbd-nbd mounter.</span></span></span><br><span class="line"><span class="meta prompt_">   #</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">   <span class="comment"># For more details</span></span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the base <span class="built_in">limit</span> of <span class="built_in">read</span> operations per second.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">BaseReadIops: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the base <span class="built_in">limit</span> of write operations per second.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">BaseWriteIops: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the base <span class="built_in">limit</span> of <span class="built_in">read</span> bytes per second.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">BaseReadBytesPerSecond: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the base <span class="built_in">limit</span> of write bytes per second.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">BaseWriteBytesPerSecond: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the <span class="built_in">limit</span> of <span class="built_in">read</span> operations per GiB.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">ReadIopsPerGiB: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the <span class="built_in">limit</span> of write operations per GiB.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">WriteIopsPerGiB: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the <span class="built_in">limit</span> of <span class="built_in">read</span> bytes per GiB.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">ReadBpsPerGiB: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) the <span class="built_in">limit</span> of write bytes per GiB.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">WriteBpsPerGiB: &lt;&gt;</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">(optional) min size of volume what use to calc qos beased on capacity.</span></span><br><span class="line"><span class="meta prompt_">   # </span><span class="language-bash">BaseVolSizeBytes:&lt;&gt;</span></span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">allowVolumeExpansion: true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">If filesystem is xfs, nouuid will be automatically added to mountOptions</span></span><br><span class="line">mountOptions:</span><br><span class="line">   - discard</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-5-创建pvc"><a href="#2-2-5-创建pvc" class="headerlink" title="2.2.5 创建pvc"></a>2.2.5 创建pvc</h4><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vim pvc.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: csi-cephfs-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">  storageClassName: csi-cephfs-sc</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-6-应用"><a href="#2-2-6-应用" class="headerlink" title="2.2.6 应用"></a>2.2.6 应用</h4><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd ceph-csi/deploy/cephfs/kubernetes</span><br><span class="line">k apply -f ../../ceph-conf.yaml # 必须应用此文件</span><br><span class="line">k apply -f ./ # 应用全部创建csi，包括deployment等</span><br><span class="line">k apply -f csi-config-map.yaml</span><br><span class="line">k apply -f csi-config-map-kms.yaml</span><br><span class="line">k apply -f secret.yaml</span><br><span class="line">k apply -f storageclass.yaml</span><br><span class="line">k apply -f pvc.yaml</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-7-创建pod"><a href="#2-2-7-创建pod" class="headerlink" title="2.2.7 创建pod"></a>2.2.7 创建pod</h4><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> pod.yaml</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: csi-cephfs-demo-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: web-server</span><br><span class="line">      image: nginx</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - name: mypvc</span><br><span class="line">          mountPath: /var/lib/www</span><br><span class="line">  volumes:</span><br><span class="line">    - name: mypvc</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: csi-cephfs-pvc</span><br><span class="line">        readOnly: false</span><br></pre></td></tr></table></figure></div>

<p>应用，即可看到挂载。对应的ceph路径为<code>/volumes/csi/csi-vol-035561d6-1f49-4477-9c6d-794382609b66/9247952c-12bd-4ecb-8845-1e2ec3bf1066/</code></p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.244.0.228:6789:/volumes/csi/csi-vol-035561d6-1f49-4477-9c6d-794382609b66/9247952c-12bd-4ecb-8845-1e2ec3bf1066  1.0G     0  1.0G   0% /var/lib/www</span><br></pre></td></tr></table></figure></div>

<h3 id="2-3-镜像列表"><a href="#2-3-镜像列表" class="headerlink" title="2.3 镜像列表"></a>2.3 镜像列表</h3><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">registry.k8s.io/sig-storage/csi-snapshotter:v8.2.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-resizer:v1.13.1</span><br><span class="line">registry.k8s.io/sig-storage/csi-provisioner:v5.1.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.13.0</span><br><span class="line">quay.io/cephcsi/cephcsi:canary</span><br></pre></td></tr></table></figure></div>

<h3 id="2-4-负载均衡"><a href="#2-4-负载均衡" class="headerlink" title="2.4 负载均衡"></a>2.4 负载均衡</h3><h4 id="2-4-1-保证每台节点均有rgw与mds服务"><a href="#2-4-1-保证每台节点均有rgw与mds服务" class="headerlink" title="2.4.1 保证每台节点均有rgw与mds服务"></a>2.4.1 保证每台节点均有rgw与mds服务</h4><h4 id="2-4-2-修改coredns"><a href="#2-4-2-修改coredns" class="headerlink" title="2.4.2 修改coredns"></a>2.4.2 修改coredns</h4><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit configmap coredns -n kube-system</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加入如下中的hosts段：</span></span><br><span class="line">Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">           lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        hosts &#123;</span><br><span class="line">          10.144.96.10 k10 postgres.service.com s3.service.com</span><br><span class="line">          10.144.96.11 k11 postgres.service.com s3.service.com</span><br><span class="line">          10.144.96.12 k12 postgres.service.com s3.service.com</span><br><span class="line">          fallthrough</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">           pods insecure</span><br><span class="line">           fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">           ttl 30</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-5-选型"><a href="#2-5-选型" class="headerlink" title="2.5 选型"></a>2.5 选型</h3><h4 id="2-5-1-Cephfs"><a href="#2-5-1-Cephfs" class="headerlink" title="2.5.1 Cephfs"></a>2.5.1 Cephfs</h4><ul>
<li><p>优点</p>
<ul>
<li><p>读取延迟低,I&#x2F;O带宽表现良好,尤其是block size较大一些的文件</p>
</li>
<li><p>灵活度高,支持k8s的所有接入模式</p>
</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>写入延迟相对较高且延迟时间不稳定</li>
</ul>
</li>
<li><p>适用场景</p>
<ul>
<li>适用于要求灵活度高(支持k8s多节点挂载特性),对I&#x2F;O延迟不甚敏感的文件读写操作,以及非海量的小文件存储支持.例如作为常用的应用&#x2F;中间件挂载存储后端.</li>
</ul>
</li>
</ul>
<h4 id="2-5-2-Ceph-RBD"><a href="#2-5-2-Ceph-RBD" class="headerlink" title="2.5.2 Ceph RBD"></a>2.5.2 Ceph RBD</h4><ul>
<li><p>优点</p>
<ul>
<li><p>I&#x2F;O带宽表现良好</p>
</li>
<li><p>读写延迟都很低</p>
</li>
<li><p>支持镜像快照,镜像转储</p>
</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>不支持多节点挂载</li>
</ul>
</li>
<li><p>适用场景</p>
<ul>
<li>对I&#x2F;O带宽和延迟要求都较高,且无多个节点同时读写数据需求的应用,例如数据库</li>
</ul>
</li>
</ul>
<h4 id="2-5-3-测试"><a href="#2-5-3-测试" class="headerlink" title="2.5.3 测试"></a>2.5.3 测试</h4><h5 id="2-5-3-1-可用工具"><a href="#2-5-3-1-可用工具" class="headerlink" title="2.5.3.1 可用工具"></a>2.5.3.1 可用工具</h5><p><strong>sysbench</strong></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/akopytov/sysbench" >akopytov&#x2F;sysbench: Scriptable database and system performance benchmark <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h5 id="2-5-3-2-写入一个大文件"><a href="#2-5-3-2-写入一个大文件" class="headerlink" title="2.5.3.2 写入一个大文件"></a>2.5.3.2 写入一个大文件</h5><ul>
<li>rbd</li>
</ul>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero  of=<span class="built_in">test</span> bs=1M count=2048</span></span><br><span class="line">2048+0 records in</span><br><span class="line">2048+0 records out</span><br><span class="line">2147483648 bytes (2.1 GB, 2.0 GiB) copied, 1.8003 s, 1.2 GB/s</span><br></pre></td></tr></table></figure></div>

<ul>
<li>fs</li>
</ul>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero  of=<span class="built_in">test</span> bs=1M count=2048</span></span><br><span class="line">2048+0 records in</span><br><span class="line">2048+0 records out</span><br><span class="line">2147483648 bytes (2.1 GB, 2.0 GiB) copied, 1.86057 s, 1.2 GB/s</span><br></pre></td></tr></table></figure></div>

<h5 id="2-5-3-3-写入一万个小文件"><a href="#2-5-3-3-写入一万个小文件" class="headerlink" title="2.5.3.3 写入一万个小文件"></a>2.5.3.3 写入一万个小文件</h5><ul>
<li>rbd</li>
</ul>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">time <span class="built_in">seq</span> 10000 | xargs -i <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=&#123;&#125;.dat bs=1024 count=1</span></span><br><span class="line">real    0m12.695s</span><br><span class="line">user    0m2.479s</span><br><span class="line">sys     0m10.661s</span><br></pre></td></tr></table></figure></div>

<ul>
<li>fs</li>
</ul>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">time <span class="built_in">seq</span> 10000 | xargs -i <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=&#123;&#125;.dat bs=1024 count=1</span></span><br><span class="line">real    0m20.365s</span><br><span class="line">user    0m3.552s</span><br><span class="line">sys     0m10.236s</span><br></pre></td></tr></table></figure></div>

<h2 id="3-其他命令"><a href="#3-其他命令" class="headerlink" title="3. 其他命令"></a>3. 其他命令</h2><pre><code>sudo ceph orch host ls
sudo ceph osd map test sys.txt
sudo ceph orch ls
sudo ceph mds metadata
sudo ceph health detail
sudo ceph -s
sudo ceph orch stop mds.test
sudo rados df
radosgw-admin user create --uid=s3 --display-name=&quot;object_storage&quot; --system
ceph orch device ls
sgdisk --zap-all /dev/nvme0n1
fdisk
</code></pre>
<h2 id="4-参考"><a href="#4-参考" class="headerlink" title="4. 参考"></a>4. 参考</h2><p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/m0_58833554/article/details/134604853" >Ceph分布式存储系统的介绍及详细安装部署过程：详细实战版（保姆级）_ceph存储部署-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/hovin/p/14746016.html" >K8S使用ceph实现持久化存储 - hovin - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://xwls.github.io/2023/02/16/ceph-cluster-install/" >Ubuntu 22.04 安装 ceph 集群 | 小汪老师 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1577952" >Ubuntu CEPH快速安装-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1604943" >Ubuntu22.04LTS基于cephadm快速部署Ceph Reef(18.2.X)集群 -阿里云开发者社区 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://bbs.huaweicloud.com/blogs/349783" >Ceph集群详细部署配置图文讲解，只要看一遍就能上手(二)【与云原生的故事】-云社区-华为云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/varden/p/15963290.html" >Ceph 服务管理之OSD服务 - Varden - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/areke/p/17730294.html" >ceph（五）CephFS部署、使用和MDS高可用实现 - areke - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/bandaoyu/article/details/111503242" >【ceph】ceph分布式存储MDS(各种状态、源码)_ceph mds-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/ask/sof/116428246" >为什么ceph没有在新节点上检测到ssd设备？-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/fa96b66f2949" >ceph 运维操作-MDS - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/5/html/file_system_guide/management-of-mds-service-using-the-ceph-orchestrator#deploying-the-mds-service-using-the-command-line-interface_fs" >2.6. 使用 Ceph Orchestrator 管理 MDS 服务 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/5/html/operations_guide/deploying-the-mds-service-using-the-command-line-interface_ops#deploying-the-mds-service-using-the-command-line-interface_ops" >9.2. 使用命令行界面部署 MDS 服务 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/areke/p/17730294.html" >ceph（五）CephFS部署、使用和MDS高可用实现 - areke - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/cyh00001/p/16754053.html" >在Ubuntu20.04下基于ceph-deploy部署ceph 16.2.10 - cyh00001 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/FutureHolmes/p/15424559.html" >Linux | Ceph | Ubuntu 中部署 Ceph 集群 - 隔江千万里 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/yaokaka/p/15156785.html" >二、Ceph的ceph-deploy部署 - yaowx - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35291429/article/details/132105630" >Ubuntu部署ceph：安装ceph-deploy遇到的问题总汇_ceph-deploy ubuntu系统-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/v-fan/p/15945956.html" >CEPH-1：ceph-deploy离线部署ceph集群及报错解决FAQ - 塔克拉玛攻城狮 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://download.ceph.com/debian-19.2.1/dists/bookworm/" >Index of &#x2F;debian-19.2.1&#x2F;dists&#x2F;bookworm&#x2F; <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud-atlas.readthedocs.io/zh-cn/latest/ceph/deploy/install_ceph_manual/add_ceph_mds.html" >Ceph集群添加MDS — Cloud Atlas: Discovery beta 文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_29974229/article/details/126970462" >Ceph故障排除: 1 pool(s) do not have an application enabled-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/chenwei8280/article/details/80785595" >PG 异常状态- active+undersized+degraded-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.orchome.com/17216" >CephFS挂载 - OrcHome <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/scaleqiao/article/details/46983709" >HEALTH_WARN mds 0 is laggy的解决方法_mount error: no mds server is up or the cluster is-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/m0_73642416/article/details/143746806" >Ceph保姆级安装教程（详细 ）_ceph 安装-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/wylfengyujiancheng/article/details/81102717" >详解cephfs几种挂载方式_cephfs挂载-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/hahaha111122222/p/15633702.html" >安装ceph (快速) 步骤三： Ceph 客户端 - 哈喽哈喽111111 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/nautilus/man/8/ceph-create-keys/" >ceph-create-keys – ceph keyring generate tool — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/areke/p/17723801.html" >ceph（二）CephX认证授权、用户管理和keyring - areke - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi" >ceph&#x2F;ceph-csi: CSI driver for Ceph <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/9209901017f5" >Ceph块存储-1·Client客户端使用 - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/hahaha111122222/p/15633702.html" >安装ceph (快速) 步骤三： Ceph 客户端 - 哈喽哈喽111111 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/CLTANG/p/4332677.html" >Ceph的客户端安装 - CL.TANG - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/mountain2011/p/12014012.html" >ceph客户端配置 - 山的那一边 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/don_chiang709/article/details/96137269" >Ceph集群搭建系列（四）：CephFS client客户端使用CephFS_ceph查看client ip-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/hahaha111122222/p/15633702.html" >安装ceph (快速) 步骤三： Ceph 客户端 - 哈喽哈喽111111 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/ask/sof/115327615" >无法从DNS SRV获取服务名称:ceph的监视器信息。-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/rook/rook/issues/3595" >unable to get monitor info from DNS SRV with service name: ceph-mon · Issue #3595 · rook&#x2F;rook <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/man/8/mount.ceph/" >mount.ceph – mount a Ceph file system — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://forum.proxmox.com/threads/ceph-mirroring-unable-to-get-monitor-info-from-dns-srv-with-service-name-ceph-mon.128066/" >[SOLVED] - CEPH Mirroring : unable to get monitor info from DNS SRV with service name: ceph-mon | Proxmox Support Forum <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://forum.proxmox.com/threads/cannot-open-ceph-conf.57636/" >Cannot open ceph.conf | Proxmox Support Forum <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/wsjhk/p/13710577.html" >【原创】K8S使用ceph-csi持久化存储之CephFS - wsjhk - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi/tree/release-v3.13" >ceph&#x2F;ceph-csi at release-v3.13 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/LiuChang-blog/p/15745774.html" >5.5 ceph 集群状态说明 - 云起时。 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi/issues/4771" >[v3.11.0] pod with pvc failed to mount from ceph cluster. (stderr: unable to get monitor info from DNS SRV with service name: ceph-mon) · Issue #4771 · ceph&#x2F;ceph-csi <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/chuyiwang/p/17612831.html" >K8S使用ceph-csi持久化存储之RBD - Chuyio - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/wsjhk/p/13710569.html" >【原创】K8S使用ceph-csi持久化存储之RBD - wsjhk - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi/issues/4548" >No such file or directory: “subvolume group ‘csi’ does not exist” · Issue #4548 · ceph&#x2F;ceph-csi <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.dqzboy.com/5353.html" >🎉 你又回来啦！ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44953658/article/details/140285939" >第33讲：K8S集群StorageClass使用Ceph CSI供应商与Cephfs文件系统集成-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.mirrorify.net/" >容器镜像加速服务 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/gengduc/article/details/134913678" >Cephadm部署使用rgw对象网关（s3cmd和Java）_cephadm rgw-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/freeitlzx/p/11281763.html" >Ceph对象存储 S3 - 李占勋 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/8/html/operations_guide/removing-the-mds-service-using-the-ceph-orchestrator_ops" >9.3. 使用 Ceph Orchestrator 删除 MDS 服务 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="http://xiaqunfeng.cc/2017/05/26/ceph-mon-clock-deviation/" >ceph mon时钟偏移问题 | 夏天的风的博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/quincy/cephadm/operations/#etc-ceph-ceph-conf" >Cephadm Operations — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/619236201" >实战篇：使用rook在k8s上搭建ceph集群 - 知乎 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://zuolaoshi.cn/article/2024/12/15/603.html" >K8S中部署Ceph | 左老师的课堂笔记 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1923891" >kubernetes 部署 rook+ceph 存储系统-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/gengduc/article/details/134913678" >Cephadm部署使用rgw对象网关（s3cmd和Java）_cephadm rgw-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43860781/article/details/121072084" >Ceph分布式存储系列（七）：对象存储RGW和S3cmd的安装配置及常用命令_对象存储常用命令-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/landhu/p/7793870.html" >s3cmd在配置后使用时提示ERROR: S3 error: 403 (InvalidAccessKeyId): The AWS Access Key Id you provided does not exist in our records. - Believer007 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/muxia_jhy/article/details/126931152" >在k8s中通过CoreDNS进行域名解析的其中三种方法_coredns添加域名解析-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/catoop/article/details/110170311" >K8s 跨 namespace 访问服务_kubernetes 跨namespace svc 访问-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/zhangmingcheng/p/18224014" >Kubernetes ExternalName类型的服务 - 人艰不拆_zmc - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37369726/article/details/121785627" >kubernetes pod间通信,跨namespace互访_在 kubernetes 集群中 pod和pod之间的访问流程-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_64228646/article/details/124317229" >Linux中一个ip绑定多个域名的详细步骤_hosts文件一个ip对应多个域名-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/chuanzhang053/p/17505044.html" >linux中，如何在&#x2F;etc&#x2F;hosts中将一个域名解析为多个IP地址？工作原理是什么？ - Zhai_David - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45853776/article/details/107356756" >hosts文件的作用以及hosts中多个ip映射一个域名地址的解析顺序_hosts 多个ip对应一个域名-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/ceph-volume/intro/" >Overview — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.bookstack.cn/read/ceph-en/de5b43971cfd01ae.md#msgr2-protocol" >Ceph Internals - msgr2 protocol - 《Ceph v15.0 Document》 - 书栈网 · BookStack <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.bookstack.cn/read/ceph-en/5a59da170fa0d6dc.md" >Configuration - Messenger v2 protocol - 《Ceph v15.0 Document》 - 书栈网 · BookStack <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/4/html/administration_guide/why-does-ceph-volume-replace-ceph-disk_admin#why-does-ceph-volume-replace-ceph-disk_admin" >6.3. 为什么 ceph-volume 替换 ceph-disk？ | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_30762005/article/details/133662232" >浅学lvm以及lvm在ceph中的应用_ceph osd 为什么采用lvm-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/iouwenbo/p/12955703.html" >Ceph删除OSD和Host的正确方法 - iouwenbo - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/8/html/operations_guide/removing-the-osd-daemons-using-the-ceph-orchestrator_ops#removing-the-osd-daemons-using-the-ceph-orchestrator_ops" >6.10. 使用 Ceph Orchestrator 删除 OSD 守护进程 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/f813d4d4ef4b" >ceph-volume 创建osd - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_50655286/article/details/144255702" >ceph相关的命令_ceph orch命令-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/5/html/operations_guide/replacing-the-osds-using-the-ceph-orchestrator_ops#replacing-the-osds-using-the-ceph-orchestrator_ops" >6.11. 使用 Ceph Orchestrator 替换 OSD | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud-atlas.readthedocs.io/zh-cn/latest/ceph/arch/bluestore.html" >Ceph后端存储引擎BlueStore — Cloud Atlas: Discovery beta 文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rados/operations/bluestore-migration/" >BlueStore Migration — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/a13568hki/article/details/118914679" >ceph 删除和添加osd_ceph删除osd-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.yeefire.com/2020_07/ceph_osd_rm.html" >从Ceph集群中删除OSD节点 | Sirius’s Blog <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/s7799653/article/details/103459051" >Ceph OSD删除与磁盘释放教程-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/a13568hki/article/details/118914679" >ceph 删除和添加osd_ceph删除osd-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/st2021/p/15026565.html" >如何将下线的OSD磁盘,重新初始化上线使用 - ST运维 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42126962/article/details/117785672" >解决重装系统后有磁盘被ceph占用问题_如何去除磁盘的sdb的ceph-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/yhao2014/article/details/44648199" >Linux格式化并重新加载磁盘_writing superblocks and filesystem-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/5/html/administration_guide/preparing-ceph-osds-using-ceph-volume_admin#preparing-ceph-osds-using-ceph-volume_admin" >7.4. 使用 ceph-volume准备 Ceph OSD | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://xcodest.me/ceph-bluestore-and-ceph-volume.html" >Ceph bluestore 和 ceph-volume - 代码杂货铺 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2314578" >Ceph：关于 Ceph 中 BlueStore 架构以及 OSD 创建的一些笔记-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/hukey/p/11910741.html" >[ ceph ] BlueStore 存储引擎介绍 - hukey - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/services/osd/" >OSD Service — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/aadc39347f18" >ceph 分层缓存 cache pool - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/li4528503/article/details/106256258" >Ceph 进阶系列（二）：如何让某个 pool 使用特定的 OSD 设备 （1 of 2，手动版，早于 luminous 版本）_ceph osd pool 能指定硬盘吗-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2187598" >ceph 指定OSD创建pool-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/boshen-hzb/p/6739368.html" >ceph中pool的管理 - 波神 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/8/html/operations_guide/removing-the-osd-daemons-using-the-ceph-orchestrator_ops#removing-the-osd-daemons-using-the-ceph-orchestrator_ops" >6.10. 使用 Ceph Orchestrator 删除 OSD 守护进程 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/xu710263124/article/details/141260193" >Ceph篇之利用shell脚本实现批量创建bucket桶-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/Operational_0624/article/details/136544498#:~:text=%E6%9C%AC%E6%96%87%E8%AF%A6%E7%BB%86%E6%8F%8F%E8%BF%B0%E4%BA%86%E5%9C%A8%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83%E6%96%AD%E7%94%B5%E5%AF%BC%E8%87%B4Ceph%E9%9B%86%E7%BE%A4%E5%AE%95%E6%9C%BA%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E6%89%8B%E5%8A%A8%E6%89%A7%E8%A1%8C%E4%B8%8A%E7%94%B5%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%8C%85%E6%8B%AC%E7%A1%AE%E8%AE%A4%E6%9C%8D%E5%8A%A1%E7%8A%B6%E6%80%81%E3%80%81%E9%9B%86%E7%BE%A4%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%81%A2%E5%A4%8D%E4%BD%BF%E7%94%A8%E6%8C%87%E4%BB%A4%E3%80%82%20%E9%87%8D%E7%82%B9%E4%BB%8B%E7%BB%8D%E4%BA%86%E5%85%B3%E9%94%AE%E6%AD%A5%E9%AA%A4%E5%92%8C%E6%A3%80%E6%9F%A5%E7%82%B9%E4%BB%A5%E7%A1%AE%E4%BF%9D%E9%9B%86%E7%BE%A4%E6%81%A2%E5%A4%8D%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C%E3%80%82%20%E5%9C%A8%E6%9E%81%E7%AB%AF%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E5%A6%82%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83,%E6%96%AD%E7%94%B5%EF%BC%8C%E9%80%A0%E6%88%90%20Ceph%20%E5%AD%98%E5%82%A8%E9%9B%86%E7%BE%A4%E5%85%A8%E5%B1%80%E5%AE%95%E6%9C%BA%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%8C%89%E7%85%A7%E6%9C%AC%E8%8A%82%E6%89%80%E7%A4%BA%E6%B5%81%E7%A8%8B%E8%BF%9B%E8%A1%8C%20Ceph%20%E9%9B%86%E7%BE%A4%E4%B8%8A%E7%94%B5%E6%81%A2%E5%A4%8D%E6%93%8D%E4%BD%9C%E3%80%82" >全局Ceph节点宕机处理-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/yuqingloveglt/articles/18567264" >ceph里面osd容量分布不均问题的处理办法 - 蓝枫居士 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/41095ae4a5f5" >ceph rgw: zone&#x2F;zone&#x2F;group&#x2F;realm - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35769071/article/details/129925760" >ceph挂载osd时出现permission denied问题_error einval: failed to connect to ceph2 (ceph2). -CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/6/html/administration_guide/starting-stopping-and-restarting-all-the-ceph-services_admin#starting-stopping-and-restarting-all-the-ceph-services_admin" >2.3. 启动、停止和重启所有 Ceph 服务 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://lihaijing.gitbooks.io/ceph-handbook/content/Troubleshooting/troubleshooting_osd.html" >2. 常见 OSD 故障处理 · Ceph 运维手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rados/operations/crush-map/" >CRUSH Maps — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/punchlinux/p/17072854.html" >创建Ceph crush运行图实现基于HDD和SSD磁盘实现数据冷热数据分类存储 - PunchLinux - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/4/html/object_gateway_configuration_and_administration_guide/configuring-bucket-sharding-rgw#configuring-bucket-sharding-rgw" >3.4. 配置 Bucket 分片 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/4/html/object_gateway_configuration_and_administration_guide/zone-group-and-zone-configuration-settings-rgw#zone-group-and-zone-configuration-settings-rgw" >5.10. zone group 和 zone 配置设置 | Red Hat Product Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/chris-cp/p/4487476.html" >ceph之crush map - 阳台 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/a011944b8a0d" >Ceph CRUSH 规则 - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45730091/article/details/105367582" >Docker查看容器挂载目录_docker 查看挂载目录-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/Man_In_The_Night/article/details/108885962" >ceph radosgw 对象存储 配额控制_radosgw-admin quota stats –quota-scope&#x3D;user-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/437491479" >Ceph获取对应存储池配额及修改 - 知乎 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/zhouzixin053/article/details/106420562" >ceph 对象网关多区部署_rgw zonegroup 和zone-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/wuxiaobingandbob/article/details/90257723" >分布式存储ceph 对象存储配置zone同步_ceph修改endpoints-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://yanyixing.github.io/2019/03/09/rgw-multi-site/" >Ceph RGW multi site 配置 | yanyx’s blog <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/zyxnhr/p/10599990.html" >012 Ceph多区域网关 - 梦中泪 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/sisimi/p/7753388.html" >创建，查看，删除pool，查看，修改pool参数命令总结 - sisimi_2017 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/fengdejiyixx/p/15186831.html" >k8s如何强制删除pod&amp;pv&amp;pvc和ns&amp;namespace方法 - 记忆流年 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi/blob/devel/examples/cephfs/storageclass.yaml" >ceph-csi&#x2F;examples&#x2F;cephfs&#x2F;storageclass.yaml at devel · ceph&#x2F;ceph-csi <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="http://strugglesquirrel.com/2020/07/24/ceph%E8%BF%90%E7%BB%B4%E5%A4%A7%E5%AE%9D%E5%89%91%E4%B9%8Bpg%E5%B8%B8%E8%A7%81%E7%8A%B6%E6%80%81%E4%BF%AE%E5%A4%8D/#:~:text=%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%E6%98%AF%EF%BC%8C%E9%87%8D%E5%BB%BA,%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%81%A2%E5%A4%8D%E6%AD%A3%E5%B8%B8%E4%BA%86" >ceph运维大宝剑之pg常见状态修复 | 奋斗的松鼠 - Blog <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.ibm.com/docs/en/storage-ceph/7?topic=groups-setting-zone-group" >Setting a zone group - IBM Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/radosgw/multisite/" >Multi-Site — Ceph Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/zorsea/article/details/104925067" >ceph部署与配置及部署过程遇到的问题解决_ceph dashboard creat-self-signed-cert 报错-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/sunbines/p/15789295.html" >【ceph运维】修改ceph集群配置 - 苏格拉底的落泪 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.ibm.com/docs/en/storage-ceph/8.0?topic=administration-configuring-multiple-realms-in-same-storage-cluster" >Configuring multiple realms in the same storage cluster - IBM Documentation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/Micha_Lu/article/details/126490260" >【ceph相关】ceph基准性能测试工具_rbd bench-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/15a986d664fe" >Ceph CrushMap及RGW Placement设置 - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/7e84139279af" >ceph 读写测试 rados bench - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/d7fcf1cb5a48" >Ceph 创建 OSD 报错 ‘GPT headers found, they must be removed’ 的处理 - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/varden/p/15946698.html" >Ceph Placement rule（副本放置规则） - Varden - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.jianshu.com/p/15a986d664fe" >Ceph CrushMap及RGW Placement设置 - 简书 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/rados/configuration/osd-config-ref/#recovery" >https://docs.ceph.com/en/latest/rados/configuration/osd-config-ref/#recovery <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/zhongguiyao/p/14256058.html" >ceph数据recovery配置策略（数据recovery流量控制） - 钟桂耀 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://gukaifeng.cn/posts/ceph-16-mo-ni-pi-pan-he-hui-fu/index.html" >Ceph 16 模拟坏盘和恢复 | GuKaifeng’s Blog <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://gukaifeng.cn/posts/linux-shan-chu-ci-pan-she-bei-shang-de-lvm/" >Linux 删除磁盘设备上的 LVM | GuKaifeng’s Blog <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/sunbines/p/15535895.html" >【ceph运维】PG相关命令 - 苏格拉底的落泪 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/zphj1987/p/13575463.html" >ceph的pg的分布的快速查看 - 武汉-磨渣 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/gzxbkk/p/7704464.html" >Ceph recover的速度控制 - 多看多学多记多实践 - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2074531" >ceph recovering速度控制-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.51cto.com/wendashuai/2491723" >Ceph PG状态及故障模拟_51CTO博客_ceph PG <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/u010953692/article/details/111909604" >osd max backfills_osd max backfills配置-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/u010953692/article/details/127672223" >ceph 数据恢复和回填速度 重建osd 加快数据恢复_ceph tell osd.* injectargs ‘–osd-max-backfills 50-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/wanger5354/article/details/135478694" >Ceph RBD和QEMU块设备qos测试_ceph rbd qos 热生效-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1680404" >Ceph 入门到实战之 RBD 块存储接口-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/ywq935/article/details/82895732" >Cephfs &amp; Ceph RBD 在k8s中的适用场景讨论及数据库性能压测_cephfs和ceph rbd的使用场景-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/ceph/ceph-csi/blob/devel/examples/rbd/storageclass.yaml" >ceph-csi&#x2F;examples&#x2F;rbd&#x2F;storageclass.yaml at devel · ceph&#x2F;ceph-csi <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://github.com/rook/rook/issues/1706" >3x performance degradation with cephfs vs rbd · Issue #1706 · rook&#x2F;rook <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44953658/article/details/139912990" >第30讲：Ceph集群RBD块存储通过CSI客户端与K8S StorageClass集成_ceph-csi rbd-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.daxuxu.info/blog/post/yuan-cheng-shi-yong-ceph-rbdkuai-she-bei/" >远程使用ceph rbd块设备 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.daxuxu.info/blog/post/ceph-kai-qi-rbdyu-yuan-cheng-gua-zai/" >ceph 开启rbd与远程挂载 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1351313" >Linux 远程挂载 Ceph RBD 磁盘-腾讯云开发者社区-腾讯云 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/gengduc/article/details/133752870" >【Ceph Block Device】块设备挂载使用-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cuiliangblog.cn/detail/section/196656143" >客户端使用RBD-崔亮的博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/hejingdong123/article/details/142058271" >ceph-radosgw 手动安装教程以及安装问题&amp;解决办法-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.cnblogs.com/doublexi/p/15619060.html" >cephfs文件系统场景 - doublexi - 博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://forum.proxmox.com/threads/how-to-delete-cephfs.54757/" >How to delete “CephFS”? | Proxmox Support Forum <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://pve.proxmox.com/pve-docs/chapter-pveceph.html#_destroy_cephfs" >Deploy Hyper-Converged Ceph Cluster <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44515412/article/details/126584230" >cephfs创建和删除pool_ceph删除pool-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> ceph部署</li>
        <li><strong>Author:</strong> Ethereal</li>
        <li><strong>Created at:</strong> 2025-03-04 21:58:41</li>
        
            <li>
                <strong>Updated at:</strong> 2025-03-31 19:13:11
            </li>
        
        <li>
            <strong>Link:</strong> https://ethereal-o.github.io/2025/03/04/ceph部署/
        </li>
        <li>
            <strong>License:</strong> This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.
        </li>
    </ul>
</div>

                </div>
            

            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2025/03/10/k8s%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8pg%E9%9B%86%E7%BE%A4/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">k8s搭建高可用pg集群</span>
                                    <span class="post-nav-item">Prev posts</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2025/02/24/k8s%E4%BD%BF%E7%94%A8gpu/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">k8s使用gpu</span>
                                    <span class="post-nav-item">Next posts</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
                <div class="comment-container">
                    <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-pjax>
        import { init } from 'https://evan.beee.top/js/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">ceph部署</div>
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E9%83%A8%E7%BD%B2"><span class="nav-text">1. 部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E4%BF%AE%E6%94%B9host%E5%B9%B6%E9%85%8D%E7%BD%AE%E4%BA%92%E4%BF%A1%EF%BC%88%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%E9%83%BD%E9%9C%80%E6%89%A7%E8%A1%8C%EF%BC%89"><span class="nav-text">1.1 修改host并配置互信（所有节点都需执行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E5%AE%89%E8%A3%85-Docker%EF%BC%88%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%E9%83%BD%E9%9C%80%E6%89%A7%E8%A1%8C%EF%BC%89"><span class="nav-text">1.2 安装 Docker（所有节点都需执行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-SSH-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%EF%BC%88%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%E9%83%BD%E9%9C%80%E6%89%A7%E8%A1%8C%EF%BC%89%E6%B3%A8%E6%84%8F%E5%BF%85%E9%A1%BB%E6%89%A7%E8%A1%8C%E4%B8%8B%E4%B8%80%E6%AD%A5%E7%9A%84%E6%8B%B7%E8%B4%9D%E5%85%AC%E9%92%A5%E6%89%8D%E7%AE%97%E5%AE%8C%E6%88%90%E5%85%8D%E5%AF%86"><span class="nav-text">1.3 SSH 免密登录（所有节点都需执行）注意必须执行下一步的拷贝公钥才算完成免密</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-%E4%BD%BF%E7%94%A8-cephadm-%E5%AE%89%E8%A3%85-ceph-%E9%9B%86%E7%BE%A4%EF%BC%88%E5%9C%A8%E4%B8%80%E5%8F%B0%E4%B8%8A%E6%89%A7%E8%A1%8C%EF%BC%89"><span class="nav-text">1.4 使用 cephadm 安装 ceph 集群（在一台上执行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%88%E5%9C%A8%E4%B8%80%E5%8F%B0%E4%B8%8A%E6%89%A7%E8%A1%8C%EF%BC%89"><span class="nav-text">1.5 初始化（在一台上执行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-6-%E9%85%8D%E7%BD%AE%E5%AF%86%E9%92%A5%EF%BC%88%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%89%A7%E8%A1%8C%EF%BC%89"><span class="nav-text">1.6 配置密钥（客户端执行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-7-%E6%8C%82%E8%BD%BD%EF%BC%88%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%89%A7%E8%A1%8C%EF%BC%89"><span class="nav-text">1.7 挂载（客户端执行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-8-%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="nav-text">1.8 客户端</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-9-%E8%AE%BE%E7%BD%AE%E6%97%B6%E9%97%B4"><span class="nav-text">1.9 设置时间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-10-%E4%B8%8B%E7%BA%BF"><span class="nav-text">1.10 下线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-11-%E5%88%86%E5%B1%82%E7%BC%93%E5%AD%98"><span class="nav-text">1.11 分层缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-12-%E5%88%92%E5%88%86OSD"><span class="nav-text">1.12 划分OSD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-13-%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D"><span class="nav-text">1.13 崩溃恢复</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-14-%E4%BF%AE%E6%94%B9rgw%E7%9A%84%E5%AD%98%E5%82%A8%E6%B1%A0"><span class="nav-text">1.14 修改rgw的存储池</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-15-%E5%8D%87%E7%BA%A7"><span class="nav-text">1.15 升级</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-16-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="nav-text">1.16 故障处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-17-%E9%85%8D%E9%A2%9D"><span class="nav-text">1.17 配额</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-18-%E6%B5%8B%E8%AF%95"><span class="nav-text">1.18 测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-19-%E4%BF%AE%E6%94%B9%E7%9B%91%E6%8E%A7"><span class="nav-text">1.19 修改监控</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E9%83%A8%E7%BD%B2%E5%88%B0k8s"><span class="nav-text">2. 部署到k8s</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E4%B8%8B%E8%BD%BDcsi"><span class="nav-text">2.1 下载csi</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-text">2.2 修改配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-%E9%95%9C%E5%83%8F%E5%88%97%E8%A1%A8"><span class="nav-text">2.3 镜像列表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="nav-text">2.4 负载均衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-%E9%80%89%E5%9E%8B"><span class="nav-text">2.5 选型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4"><span class="nav-text">3. 其他命令</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E5%8F%82%E8%80%83"><span class="nav-text">4. 参考</span></a></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2023</span>
              -
            
            2025&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Ethereal</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        VISITOR COUNT&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        TOTAL PAGE VIEWS&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a></span>
                <br>
            <span class="theme-version-container">THEME&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.2.1</a>
        </div>
        
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/navbarShrink.js"></script>

<script src="/js/tools/scrollTopBottom.js"></script>

<script src="/js/tools/lightDarkSwitch.js"></script>





    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts pjax">
    
        
<script src="/js/tools/tocToggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
